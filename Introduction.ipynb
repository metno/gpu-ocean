{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "This software is part of GPU Ocean. \n",
    "\n",
    "Copyright (C) 2019 SINTEF Digital\n",
    "Copyright (C) 2019 Norwegian Meteorological Institute\n",
    "\n",
    "This notebook provides the description of the code found in this \n",
    "software package, which is provided as supplementary material to\n",
    "\"Massively Parallel Implicit Equal-Weights Particle Filter for Ocean Drift Trajectory Forecasting\" by Holm, Sætra and van Leeuwen.\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary Software for Massively Parallel Implicit Equal-Weights Particle Filter for Ocean Drift Trajectory Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This software package is provideded as a supplement to the paper *Massively Parallel Implicit Equal-Weights Particle Filter for Ocean Drift Trajectory Forecasting* written by Håvard Heitlo Holm, Martin Lilleeng Sætra and Peter Jan van Leeuwen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "The main purpose of this release of the GPU Ocean software is to provide code can be usedto reproduce and regenerate results that are presented in the above paper.\n",
    "\n",
    "The code is written in Python, whereas the numerical schemes are implemented in CUDA and accessed through the PyCUDA library.\n",
    "\n",
    "The main data assimilation experiments are provided as Python scripts, whereas the post-processing of the results and visualization is generated in Jupyter Notebooks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data \n",
    "\n",
    "In order to run the experiments or regenerate our results, you need the initial states and ensemble results.\n",
    "\n",
    "Here you have two options:\n",
    "1. The true state and initial data used in the paper, and the files containing the complete results that we presented are available as *Supplementary Data for Massively Parallel Implicit Equal-Weights Particle Filter for Ocean Drift Trajectory Forecasting* under DOI [10.5281/zenodo.3457538](https://www.doi.org/10.5281/zenodo.3457538). The repository contains the following folders:\n",
    "  * `true_state/` True state and observations.\n",
    "  * `ensemble_init/` Ensemble initial states ($N_e = 100$)\n",
    "  * `forecast_results/` Results from the data-assimilation and forecasting experiments\n",
    "  * `rank_histogram/` Results from the experiments for obtaining the rank histograms.\n",
    "  * `computational_performance/` Results from the computational performance experiments.\n",
    "\n",
    "  In order to use these files, all the notebooks mentioned above expect the data repository to be located in `gpu_ocean/demos/DAPaper/presented_data/`, so that the NetCDF file containing the truth is available as `gpu_ocean/demos/DAPaper/presented_data/true_state/double_jet_case_truth.nc`.\n",
    "\n",
    "2. You can generate your own true state and initial conditions, and then run the data-assimilation experiments. Instructions on how to do this is found below. **Note:** If you do this, you will be required to change some in order to use your newly generated true state/initial ensemble/forecast results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organization of the code\n",
    "The code is organized as follows:\n",
    "- `gpu_ocean/demos/DAPaper/` contains **Jupyter Notebooks** related to the experiments and figures presented in the paper\n",
    "- `gpu_ocean/demos/DAPaper/scripts/` contains **Python scripts** related to the experiments and figures presented in the paper\n",
    "- `gpu_ocean/SWESimulators/` contains python modules for each scheme and a selection of utility classes and functions.\n",
    "- `gpu_ocean/SWESimulators/gpu_kernels/` contains the CUDA implementations of the numerical schemes and the implicit equal-weights particle filter.\n",
    "- `gpu_ocean/tests/` contains regression tests.\n",
    "\n",
    "Small result files produced for the paper can also be found under the `notebooks/`-folder, and the subfolders not mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation \n",
    "\n",
    "### CUDA\n",
    "In order to run this code, you need to have access to a CUDA enabled GPU, with CUDA toolkit and appropriate drivers installed. If you are on Windows, you also need to have installed Visual Studios and add the path to its bin folder in PATH. This is so that pycuda can find a C++ compiler.\n",
    "\n",
    "\n",
    "### Python packages\n",
    "#### Conda\n",
    "We recommend that you set up your python environment using Conda as follows:\n",
    "- Install [miniconda](https://conda.io/miniconda.html) (which is a minimal subset of Anaconda)\n",
    "- Install jupyter notebook (unless you already have it installed on your system) by opening a terminal (or Anaconda prompt if on Windows) and type\n",
    "    ```\n",
    "    conda install -c conda-forge jupyter\n",
    "    ```\n",
    "- Install the conda extensions that allows jupyter notebook to select conda environments as kernels:\n",
    "    ```\n",
    "    conda install -c conda-forge nb_conda_kernels\n",
    "    ```\n",
    "- Create a new conda environment according to the environment file in this repository\n",
    "    ```\n",
    "    conda env create -f conda_environment.yml\n",
    "    ```\n",
    "    **or**, if you want to use the exact package versions originally used to produce our results, run\n",
    "    ```\n",
    "    conda env create -f conda_dapaper_versions.yml\n",
    "    ```\n",
    "\n",
    "You should now be able to start a jupyter notebook server, open one of our notebooks, select the conda environment 'gpuocean' as kernel, and run the code. \n",
    "\n",
    "For running python scripts, remember to first activate the environment:\n",
    "```\n",
    "conda activate gpuocean\n",
    "```\n",
    "\n",
    "\n",
    "#### Pip\n",
    "A requirements file is available at `gpu_ocean/requirements.txt` that can be used to install all requirements on pip. *Disclaimer:* this is not tested - please check the files containing the conda environments to look for missing packages.\n",
    "\n",
    "### Test your installation\n",
    "Before running data-assimilation experiments you should check that everything works as expected by running the following tests:\n",
    "```\n",
    "$ cd gpu_ocean/tests/\n",
    "$ python basic_pycuda_tests.py\n",
    "$ python oneLayer_2D_tests.py 0\n",
    "$ python particle_filter_tests.py 0\n",
    "$ python random_numbers.py 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run data-assimilation experiments\n",
    "\n",
    "The following scripts are related to running your own data-assimilation experiments, and they are all found in `gpu_ocean/demos/DAPaper/scripts/`. \n",
    "\n",
    "* `generate_truth.py` Generates a true state along with observations. \n",
    "* `generate_ensemble_init.py` Generates an ensemble of initial states.\n",
    "* `run_experiment.py`  Runs data-assimilation and drift trajectory forecasts.\n",
    "* `all_forecasts.sh` Runs all the six data-assimilation and forecasting experiments described in the paper.\n",
    "\n",
    "Finally, the results can be investigated by using the notebook `PostProcessDAExperiment.ipynb` located in `gpu_ocean/demos/DAPaper/`.\n",
    "It reads the results from one experiment at a time, and produces several visualizations of the results. \n",
    "\n",
    "\n",
    "### Experiments for rank histograms\n",
    "* `rank_histogram_experiment.py` This script runs a (potentially) large number of shorter forecasting experiments which can be used to generate rank histograms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate figures from the paper\n",
    "All notebooks are found in `gpu_ocean/demos/DAPaper/`\n",
    "\n",
    "These notebooks assume that you have downloaded the data *Supplementary Data for Massively Parallel Implicit Equal-Weights Particle Filter for Ocean Drift Trajectory Forecasting* under DOI [10.5281/zenodo.3457538](https://www.doi.org/10.5281/zenodo.3457538), and copied/moved this package into `gpu_ocean/demos/DAPaper/data_from_paper/`\n",
    "\n",
    "If you wish to use these notebooks to plot results from your own experiments, you will have to change some paths in the notebooks. They should not be too hard to find.\n",
    "\n",
    "- Figure 2: [ModelErrors.ipynb](gpu_ocean/demos/DAPaper/ModelErrors.ipynb) Illustrate how the model error is created.\n",
    "- Figure 3: [IEWPFLoopFigures.ipynb](gpu_ocean/demos/DAPaper/IEWPFLoopFigures.ipynb) Creates the small figures within the figure that explains the complete IEWPF algorithm.\n",
    "- Figure 4: [StepByStepIEWPF.ipynb](gpu_ocean/demos/DAPaper/StepByStepIEWPF.ipynb) Takes us through the process of using the optimal proposal pull onto a particle, as a step in the IEWPF algorithm.\n",
    "- Figure 5: [SVDnnz.ipynb](gpu_ocean/demos/DAPaper/SVDnnz.ipynb) Illustrates the non-zero pattern for applying the local proposal covariance structure.\n",
    "- Figure 6-7: [InvestigateTruth.ipynb](gpu_ocean/demos/DAPaper/InvestigateTruth.ipynb) Plotting the true state at different times, and looking at the trajectories of some of the true drifters.\n",
    "- Figure 9: [RankHistograms.ipynb](gpu_ocean/demos/DAPaper/RankHistograms.ipynb) Post-processing of the results from the rank histogram experiments, and generates the rank histograms.\n",
    "- Figure 10-14: [PostProcessDAExperiment.ipynb](gpu_ocean/demos/DAPaper/PostProcessDAExperiment.ipynb) Main experiment post processing notebook. Plots ensemble means/var during both the data-assimilation and forecasting periods, as well as drift trajectory forecasts for a wide range of drifters.\n",
    "- Figure 15: [ForecastErrors.ipynb](gpu_ocean/demos/DAPaper/ForecastErrors.ipynb) Plots the error statistics \n",
    "- Figure 16: [ParticleFilter_SIR.ipynb](gpu_ocean/demos/DAPaper/ParticleFilter_SIR.ipynb) Runs basic particle filter experiments and shows results similar to those presented in the paper.\n",
    "- Figure 17-18: [ComputationalPerformancePlotting.ipynb](gpu_ocean/demos/DAPaper/ComputationalPerformancePlotting.ipynb) Creates plots for computational performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc other scripts/notebooks\n",
    "\n",
    "All path are relative to `gpu_ocean/demos/DAPaper/`\n",
    "\n",
    "* `scripts/run_model.py` Script that runs a single model with or without the model error. Used to profile the model and model errors, and measure computational performance.\n",
    "* `InvestigateEnsemble.ipynb` Looks at the ensemble mean and variance just before and after the first data-assimilation step.\n",
    "* `ModelErrorPerformance_BlockSizeExperiment.ipynb` Testing the optimal block size configurations for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inconsistency with the paper\n",
    "\n",
    "There is one inconsistency with the paper regarding the naming of the static observations. The observations of moored buoys (moorings) described in the paper are termed as \"buoys\" in the code. For running a data-assimilation experiment based on the west moorings only, you therefore need to run, e.g.,\n",
    "```\n",
    "$ python run_experiments.py -N 100 --observation_type buoys --buoy_area west \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gpuocean] *",
   "language": "python",
   "name": "conda-env-gpuocean-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
