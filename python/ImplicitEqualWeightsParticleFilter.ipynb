{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "This notebook sets up and runs a set of benchmarks to compare\n",
    "different numerical discretizations of the SWEs\n",
    "\n",
    "Copyright (C) 2016  SINTEF ICT\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implicit Equal Weights Particle Filter\n",
    "\n",
    "This notebook implements prototyping and example/demo of the Implicit Equal Weights Particle Filter (IEWPF).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "from scipy.special import lambertw\n",
    "\n",
    "import pyopencl\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#Set large figure sizes\n",
    "rc('figure', figsize=(16.0, 12.0))\n",
    "rc('animation', html='html5')\n",
    "matplotlib.rcParams['contour.negative_linestyle'] = 'solid'\n",
    "\n",
    "#Import our simulator\n",
    "from SWESimulators import CDKLM16, PlotHelper, Common\n",
    "\n",
    "from SWESimulators import BathymetryAndICs as BC\n",
    "from SWESimulators import OceanStateNoise\n",
    "from SWESimulators import OceanNoiseEnsemble\n",
    "from SWESimulators import BaseOceanStateEnsemble\n",
    "from SWESimulators import DataAssimilationUtils as dautils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make sure we get compiler output from OpenCL\n",
    "os.environ[\"PYOPENCL_COMPILER_OUTPUT\"] = \"1\"\n",
    "\n",
    "#Set which CL device to use, and disable kernel caching\n",
    "if (str.lower(sys.platform).startswith(\"linux\")):\n",
    "    os.environ[\"PYOPENCL_CTX\"] = \"0\"\n",
    "else:\n",
    "    os.environ[\"PYOPENCL_CTX\"] = \"1\"\n",
    "os.environ[\"CUDA_CACHE_DISABLE\"] = \"1\"\n",
    "os.environ[\"PYOPENCL_COMPILER_OUTPUT\"] = \"1\"\n",
    "os.environ[\"PYOPENCL_NO_CACHE\"] = \"1\"\n",
    "\n",
    "#Create OpenCL context\n",
    "cl_ctx = pyopencl.create_some_context()\n",
    "cl_queue = pyopencl.CommandQueue(cl_ctx)\n",
    "print \"Using \", cl_ctx.devices[0].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble\n",
    "\n",
    "We need an ensemble where each particle\n",
    "- runs an independent ocean model\n",
    "- applies a localized small-scale error\n",
    "- observes the drifter prosition of the syntetic truth, and estimate the underlying velocity field at that point\n",
    "- look-up the particles' velocity at the same point as where the drifter was observed\n",
    "\n",
    "Needs to be done:\n",
    "- Initialize models (create netcdf with init, add error with amp 10*q0(?), put drifter into a small area of the \n",
    "- make useful plots to evaluate the results\n",
    "    - Suggestion: 3-line [eta, hu, hv] plot, with truth, ensemble (mean field with individual drifters), mean-square diff?\n",
    "    - 3x3/4x4/5x5 plot of eta from different ensemble members?\n",
    "    - Standard animation of a single ensemble member.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create initial condition for ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# DEFINE PARAMETERS\n",
    "\n",
    "#Coriolis well balanced reconstruction scheme\n",
    "nx = 40\n",
    "ny = 40\n",
    "\n",
    "dx = 4.0\n",
    "dy = 4.0\n",
    "\n",
    "dt = 0.05\n",
    "g = 9.81\n",
    "r = 0.0\n",
    "\n",
    "f = 0.05\n",
    "beta = 0.0\n",
    "\n",
    "ghosts = np.array([2,2,2,2]) # north, east, south, west\n",
    "validDomain = np.array([2,2,2,2])\n",
    "boundaryConditions = Common.BoundaryConditions(2,2,2,2)\n",
    "\n",
    "# Define which cell index which has lower left corner as position (0,0)\n",
    "x_zero_ref = 2\n",
    "y_zero_ref = 2\n",
    "\n",
    "dataShape = (ny + ghosts[0]+ghosts[2], \n",
    "             nx + ghosts[1]+ghosts[3])\n",
    "dataShapeHi = (ny + ghosts[0]+ghosts[2]+1, \n",
    "             nx + ghosts[1]+ghosts[3]+1)\n",
    "\n",
    "eta0 = np.zeros(dataShape, dtype=np.float32, order='C');\n",
    "eta0_extra = np.zeros(dataShape, dtype=np.float32, order='C')\n",
    "hv0 = np.zeros(dataShape, dtype=np.float32, order='C');\n",
    "hu0 = np.zeros(dataShape, dtype=np.float32, order='C');\n",
    "waterDepth = 10.0\n",
    "Hi = np.ones(dataShapeHi, dtype=np.float32, order='C')*waterDepth\n",
    "\n",
    "# Add disturbance:\n",
    "if True:\n",
    "    rel_grid_size = nx*1.0/dx\n",
    "    BC.addBump(eta0, nx, ny, dx, dy, 0.3, 0.5, 0.05*rel_grid_size, validDomain)\n",
    "    eta0 = eta0*0.3\n",
    "    BC.addBump(eta0, nx, ny, dx, dy, 0.7, 0.3, 0.10*rel_grid_size, validDomain)\n",
    "    eta0 = eta0*(-1.3)\n",
    "    BC.addBump(eta0, nx, ny, dx, dy, 0.15, 0.8, 0.03*rel_grid_size, validDomain)\n",
    "    eta0 = eta0*1.0\n",
    "    BC.addBump(eta0, nx, ny, dx, dy, 0.6, 0.75, 0.06*rel_grid_size, validDomain)\n",
    "    BC.addBump(eta0, nx, ny, dx, dy, 0.2, 0.2, 0.01*rel_grid_size, validDomain)\n",
    "    eta0 = eta0*(-0.03)\n",
    "    BC.addBump(eta0_extra, nx, ny, dx, dy, 0.5, 0.5, 0.4*rel_grid_size, validDomain)\n",
    "    eta0 = eta0 + 0.02*eta0_extra\n",
    "    BC.initializeBalancedVelocityField(eta0, Hi, hu0, hv0, f, beta, g, nx, ny, dx ,dy, ghosts)\n",
    "    eta0 = eta0*0.5\n",
    "\n",
    "\n",
    "if 'sim' in globals():\n",
    "    sim.cleanUp()\n",
    "if 'ensemble' in globals():\n",
    "    ensemble.cleanUp()\n",
    "    \n",
    "q0 = 0.5*dt*f/(g*waterDepth)\n",
    "print \"q0: \", q0\n",
    "print \"[f, g, H]\", [f, g, waterDepth]\n",
    "print \"f/gH: \", f/(g*waterDepth)\n",
    "print \"gH/f: \", g*waterDepth/f\n",
    "\n",
    "reload(CDKLM16)\n",
    "reload(BaseOceanStateEnsemble)\n",
    "reload(OceanNoiseEnsemble)\n",
    "reload(PlotHelper)\n",
    "sim = CDKLM16.CDKLM16(cl_ctx, eta0, hu0, hv0, Hi, \\\n",
    "                      nx, ny, dx, dy, dt, g, f, r, \\\n",
    "                      boundary_conditions=boundaryConditions, \\\n",
    "                      write_netcdf=False, \\\n",
    "                      small_scale_perturbation=True, \\\n",
    "                      small_scale_perturbation_amplitude=q0)\n",
    "\n",
    "ensemble_size = 3\n",
    "\n",
    "ensemble = OceanNoiseEnsemble.OceanNoiseEnsemble(ensemble_size, cl_ctx,  \n",
    "                                                 observation_type=dautils.ObservationType.DirectUnderlyingFlow)\n",
    "ensemble.setGridInfoFromSim(sim)\n",
    "ensemble.setStochasticVariables(#observation_variance_factor=2.0,\n",
    "                                observation_variance = 0.01**2,\n",
    "                                small_scale_perturbation_amplitude=q0)\n",
    "                                #initialization_variance_factor_ocean_field=50)\n",
    "ensemble.init()\n",
    "\n",
    "fig = plt.figure()\n",
    "plotter = PlotHelper.EnsembleAnimator(fig, ensemble, trueStateOnly=True)\n",
    "\n",
    "T = 2\n",
    "sub_t = 300*dt\n",
    "def animate(i):\n",
    "    if (i>0):\n",
    "        t = ensemble.step(sub_t)\n",
    "    else:\n",
    "        t = 0.0\n",
    "\n",
    "    plotter.plot(ensemble);\n",
    "\n",
    "    fig.suptitle(\"Ensemble = \" + \"{:04.0f}\".format(t) + \" s\", fontsize=18)\n",
    "\n",
    "    if (i%10 == 0):\n",
    "        print \"{:03.0f}\".format(100*i / T) + \" % => t=\" + str(t) \n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, range(T), interval=100)\n",
    "plt.close(anim._fig)\n",
    "anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ensemble.plotEnsemble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_dt = ensemble.findLargestPossibleTimeStep()\n",
    "print \"Largest possible timestep with this case: \", max_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = ensemble.plotDistanceInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Implementing IEWPF\n",
    "\n",
    "The IEWPF algorithm for the observation at time $t^m$ is applyed to the model at time $t^{m-1}$.\n",
    "The algorithm consists of the following steps:\n",
    "1. Find target weight using only deterministic evolution of the model from $t^{m-1}$ to $t^m$.\n",
    "- Draw a sample from $\\xi \\sim N(0,P)$.\n",
    "- Move particles towards observation using a applying some scaling of $\\xi$\n",
    "\n",
    "Some challenges:\n",
    "- As long as we have one and only one drifter, constant $H(x,y)$ and double periodic boundary conditions, the linear problem within step 1 has the same matrix for any observation. This matrix should therefore be pre-calculated.\n",
    "- During the creation of $\\xi$ we need the random numbers, so using functionality of the OceanNoiseClass would be nice.\n",
    "\n",
    "\n",
    "Questions:\n",
    "- Should the IEWPF subroutines/functions/methods be under its own class? Or under the OceanNoiseClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance structures\n",
    "The model error is sampled from $N(0, Q)$, where \n",
    "$$Q = Q^{1/2} Q^{1/2,T} = U_{GB} \\tilde{Q}^{1/2} \\tilde{Q}^{1/2} U_{GB}^T.$$\n",
    "Here, $\\tilde{Q}^{1/2}$ is the SOAR function, and $U_{GB}$ is the operator that map $\\eta$ to $[\\eta, hu, hv]^T$, such that the state is in geostrophic balance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0\n",
    "Rum the model to observation time, obtain w_rest, and run the particles to observation time without using the stochastic term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = ensemble.step_truth(dt, stochastic=True)\n",
    "#w_rest = -np.log(ensemble.getGaussianWeight())\n",
    "w_rest = -np.log(np.ones(ensemble.getNumParticles())/(1.0 + ensemble.getNumParticles()))\n",
    "t = ensemble.step_particles(dt, stochastic=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 1\n",
    "\n",
    "The full covariance matrix can be written as\n",
    "$$ Q = Q^{1/2} Q^{1/2,T} = U_{GB} \\tilde{Q}^{1/2} \\tilde{Q}^{1/2} U_{GB}^T $$\n",
    "so that \n",
    "$$ HQH^T = H U_{GB} \\tilde{Q}^{1/2} \\tilde{Q}^{1/2} U_{GB}^T  H^T$$\n",
    "\n",
    "For Step 1 we first need to find $$S := (H Q H^T + R)^-1,$$ which we also will need for later.\n",
    "We therefore store S, before finding the target weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "debug = False\n",
    "\n",
    "def showMatrices(x, y, title, z = None):\n",
    "    num_cols = 2\n",
    "    if z is not None:\n",
    "        num_cols = 3\n",
    "    fig = plt.figure(figsize=(num_cols*2,2))\n",
    "    plt.subplot(1,num_cols,1)\n",
    "    plt.imshow(x.copy(), origin=\"lower\", interpolation=\"None\")\n",
    "    plt.xlabel('(%.2E, %.2E)' % (np.min(x), np.max(x)))\n",
    "    plt.subplot(1,num_cols,2)\n",
    "    plt.imshow(y.copy(), origin=\"lower\", interpolation=\"None\")\n",
    "    plt.xlabel('(%.2E, %.2E)' % (np.min(y), np.max(y)))\n",
    "    if z is not None:\n",
    "        plt.subplot(1, num_cols, 3)\n",
    "        plt.imshow(z.copy(), origin=\"lower\", interpolation=\"None\")\n",
    "        plt.xlabel('(%.2E, %.2E)' % (np.min(z), np.max(z)))\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "# Copied from RandomNumberGenerator.ipynb  \n",
    "def SOAR_Q(a_x, a_y, b_x, b_y, dx, dy, q0, L):\n",
    "    dist = np.sqrt( dx*dx*(a_x - b_x)**2  +  dy*dy*(a_y - b_y)**2)\n",
    "    return q0*(1.0 + dist/L)*np.exp(-dist/L)\n",
    "\n",
    "debug = True\n",
    "def createS(ensemble, const_H, debug=False):\n",
    "    \"\"\"\n",
    "    Create the 2x2 matrix S = (HQH^T + R)^-1\n",
    "    \n",
    "    Constant as long as\n",
    "     - one drifter only,\n",
    "     - H(x,y) = const, and\n",
    "     - double periodic boundary conditions\n",
    "    \"\"\"\n",
    "    \n",
    "    dt = ensemble.dt\n",
    "    dx = ensemble.dx\n",
    "    dy = ensemble.dy\n",
    "    geoBalanceConst = ensemble.g*const_H/(2.0*ensemble.f)\n",
    "    \n",
    "    # These should be read from a OceanStateNoise object?\n",
    "    q0 = ensemble.small_scale_perturbation_amplitude\n",
    "    L = 0.75*dx \n",
    "    \n",
    "    # Local storage for x and y correlations:\n",
    "    x_corr = np.zeros((7,7))\n",
    "    y_corr = np.zeros((7,7))\n",
    "    tmp_x = np.zeros((7,7))\n",
    "    tmp_y = np.zeros((7,7))\n",
    "    \n",
    "    # Mid_coordinates:\n",
    "    mid_i, mid_j = 3, 3\n",
    "    \n",
    "    # Fill the buffers with U_{GB}^T H^T\n",
    "    x_corr[mid_j+1, mid_i] = -geoBalanceConst/dy\n",
    "    x_corr[mid_j-1, mid_i] =  geoBalanceConst/dy\n",
    "    y_corr[mid_j, mid_i+1] =  geoBalanceConst/dx\n",
    "    y_corr[mid_j, mid_i-1] = -geoBalanceConst/dx\n",
    "    if debug: showMatrices(x_corr, y_corr, \"$U_{GB}^T  H^T$\")\n",
    "    \n",
    "    # Apply the SOAR function to fill x and y with 7x5 and 5x7 respectively\n",
    "    # First for x:\n",
    "    for j,i in [mid_j+1, mid_i], [mid_j-1, mid_i]:\n",
    "        for b in range(j-2, j+3):\n",
    "            for a in range(i-2, i+3):\n",
    "                tmp_x[b, a] += x_corr[j,i]*SOAR_Q(a, b, i, j, dx, dy, q0, L)\n",
    "    # Then for y:\n",
    "    for j,i in [mid_j, mid_i+1], [mid_j, mid_i-1]:\n",
    "        for b in range(j-2, j+3):\n",
    "            for a in range(i-2, i+3):\n",
    "                #print SOAR_Q(a, b, i, j, dx, dy, q0, L)\n",
    "                tmp_y[b, a] += y_corr[j,i]*SOAR_Q(a, b, i, j, dx, dy, q0, L)\n",
    "    if debug: showMatrices(tmp_x, tmp_y, \"$Q_{SOAR} U_{GB}^T H^T$\")   \n",
    "        \n",
    "    # Apply the SOARfunction again to fill the points needed to find drift in (mid_i, mid_j)\n",
    "    # For both x and y:\n",
    "    # This means that we only need to evaluate Q_{SOAR} Q_{SOAR} U_{GB}^T H^T at four points\n",
    "    for j,i in [mid_j+1, mid_i], [mid_j-1, mid_i], [mid_j, mid_i-1], [mid_j, mid_i+1]:\n",
    "        x_corr[j,i] = 0\n",
    "        y_corr[j,i] = 0\n",
    "        for b in range(j-2, j+3):\n",
    "            for a in range(i-2, i+3):\n",
    "                SOAR_Q_res = SOAR_Q(a, b, i, j, dx, dy, q0, L)\n",
    "                x_corr[j,i] += tmp_x[b, a]*SOAR_Q_res\n",
    "                y_corr[j,i] += tmp_y[b, a]*SOAR_Q_res\n",
    "        if debug: print \"(j, i ,x_corr[j,i], y_corr[j,i]): \", (j, i ,x_corr[j,i], y_corr[j,i])\n",
    "    if debug: showMatrices(x_corr, y_corr, \"$Q_{SOAR} Q_{SOAR} U_{GB}^T H^T$\")\n",
    "       \n",
    "    # geostrophic balance:\n",
    "    x_hu = -geoBalanceConst*(x_corr[mid_j+1, mid_i  ] - x_corr[mid_j-1, mid_i  ])/dy\n",
    "    x_hv =  geoBalanceConst*(x_corr[mid_j  , mid_i+1] - x_corr[mid_j  , mid_i-1])/dx\n",
    "    y_hu = -geoBalanceConst*(y_corr[mid_j+1, mid_i  ] - y_corr[mid_j-1, mid_i  ])/dy\n",
    "    y_hv =  geoBalanceConst*(y_corr[mid_j  , mid_i+1] - y_corr[mid_j  , mid_i-1])/dx \n",
    "    \n",
    "    # Structure the information as a  \n",
    "    HQHT = np.matrix([[x_hu, y_hu],[x_hv, y_hv]])    \n",
    "    if debug: print \"HQHT\\n\", HQHT\n",
    "    if debug: print \"ensemble.observation_cov\\n\", ensemble.observation_cov\n",
    "    S_inv = HQHT + ensemble.observation_cov\n",
    "    if debug: print \"S_inv\\n\", S_inv\n",
    "    S = np.linalg.inv(S_inv)\n",
    "    if debug: print \"S\\n\", S\n",
    "    return S\n",
    "\n",
    "print \"-----------\"\n",
    "S = createS(ensemble, 10.0, debug=True)\n",
    "print \"-----------\"\n",
    "print \"S: \", S\n",
    "\n",
    "print \"ensemble.observation_cov\"\n",
    "print ensemble.observation_cov\n",
    "print \"np.linalg.inv(ensemble.observation_cov)\"\n",
    "print np.linalg.inv(ensemble.observation_cov)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expected $HQH^T$ to be a full $2 \\times 2$ matrix, but we see now that the $x$ and $y$ coordinate of the drifter is uncorrelated.\n",
    "\n",
    "When one thinks about it, this makes sense. Even though we know the $x$ position of a drifter, we would have no knowledge of the $y$ position of it. \n",
    "\n",
    "The same argument can be used about the velocities. Can we really say anything about the $hu$ in a cell based on the value of $hv$ in the same cell? From $hu(x_i, y_j)$ alone, we can not say whether all the momentum is in $x$-direction, or if it is just a part of the total momentum, which also has a $y$ component. Even though the geostrophic balance generate rotating velocity fields, we will have no knowledge on where in the rotation we are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# As we have S = (HQH^T + R)^-1, we can do step 1 of the IEWPF algorithm\n",
    "def obtainTargetWeight(ensemble, S, w_rest, debug=False):\n",
    "    d = ensemble.getInnovations()\n",
    "    Ne = ensemble.getNumParticles()\n",
    "    c = np.zeros(Ne)\n",
    "    for i in range(Ne):\n",
    "        e = np.dot(S, d[i,:])\n",
    "        c[i] = w_rest[i] + 0.5*np.dot(e,d[i,:])\n",
    "        #c[i] =  0.5*np.dot(e,d[i,:])\n",
    "        if debug: print \"c[\" + str(i) + \"]: \", c[i]\n",
    "        if debug: print \"exp(-c[\" + str(i) + \"]: \", np.exp(-c[i])\n",
    "    return np.min(c)\n",
    "\n",
    "target_weight = obtainTargetWeight(ensemble, S, w_rest, True)\n",
    "print \"target_weight: \", target_weight\n",
    "print \"current weights: \"\n",
    "print ensemble.getGaussianWeight()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "Draw samples from $\\xi \\sim N(0, P)$, where \n",
    "$$ P = (Q^{-1}+ H^T R^{-1} H)^{-1}. $$\n",
    "With some additional linear algebra magic, $P$ can also be written as\n",
    "$$ P = Q - QH^T (HQH^T + R)^{-1} H Q.$$\n",
    "Defining $S := (HQH^T + R)^{-1}$, it is straight forward to write $P$ as\n",
    "$$P = Q - Q H^T S H Q \\\\ = Q^{1/2}(I - Q^{1/2, T}H^T S H Q^{1/2}) Q^{1/2, T}$$\n",
    "By using the two-step covariance structure, we get\n",
    "$$ P = U_{GB} \\tilde{Q}^{1/2} \\left[ I - \\tilde{Q}^{1/2} U_{GB}^T H^T S H  U_{GB} \\tilde{Q}^{1/2} \\right] \\tilde{Q}^{1/2} U_{GB}^T $$\n",
    "\n",
    "In order to produce $\\xi \\sim N(0,P)$, we draw $\\tilde{\\xi} \\sim N(0, I)$, where $\\tilde{\\xi} \\in \\mathbb{R}^{N_x}$, and find $\\xi = P^{1/2} \\tilde{\\xi}$.\n",
    "We can write\n",
    "$$P = P^{1/2} P^{1/2, T},$$\n",
    "if we can find the singular value decomposition (SVD) of the paranthesis in the expression for $P$.\n",
    "\n",
    "Assume that we can write\n",
    "$$ U \\Sigma V^H = I - \\tilde{Q}^{1/2} U_{GB}^T H^T S H  U_{GB} \\tilde{Q}^{1/2},$$\n",
    "we can write \n",
    "$$ P = U_{GB} \\tilde{Q}^{1/2} U \\Sigma^{1/2} \\Sigma^{1/2} V^H \\tilde{Q}^{1/2} U_{GB}^T.$$\n",
    "\n",
    "We can now draw $\\xi \\sim N(0,P)$ as\n",
    "$$ \\xi = U_{GB} \\tilde{Q}^{1/2} U \\Sigma^{1/2} \\tilde{\\xi}$$.\n",
    "\n",
    "\n",
    "\n",
    "### Note\n",
    "\n",
    "Since $H$ depends on the position of the drifter, the SVD also depends on the position of the drifter. However, as long as \n",
    "- the depth is constant over the entire domain,\n",
    "- $\\Delta x = \\Delta y$,\n",
    "- $f$ is constant, and \n",
    "- there are periodic boundary conditions,\n",
    "\n",
    "the covariance structure around the observed drifter is the same and independent of the drifters position.\n",
    "We can then create this structure only once, and apply it to different parts of $\\tilde{\\xi}$.\n",
    "\n",
    "The non-identity part of the SVD input is an area consisting of $7 \\times 7$ cells, meaning that $U \\Sigma^{1/2}$ will be a $49 \\times 49$ matrix.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _periodic_SOAR_Q(a_x, a_y, b_x, b_y, dx, dy, nx, ny, q0, L):\n",
    "    dist_x = min((a_x - b_x)**2, (a_x - (b_x + nx))**2, (a_x - (b_x - nx))**2)\n",
    "    dist_y = min((a_y - b_y)**2, (a_y - (b_y + ny))**2, (a_y - (b_y - ny))**2)\n",
    "    \n",
    "    dist = np.sqrt( dx*dx*dist_x  +  dy*dy*dist_y)\n",
    "    \n",
    "    return q0*(1.0 + dist/L)*np.exp(-dist/L)\n",
    "\n",
    "def _createCutoffSOARMatrixQ(ensemble, nx=None, ny=None, cutoff=2):\n",
    "    if nx is None:\n",
    "        nx = ensemble.nx\n",
    "    if ny is None:\n",
    "        ny = ensemble.ny\n",
    "    dx = ensemble.dx\n",
    "    dy = ensemble.dy\n",
    "    q0 = ensemble.small_scale_perturbation_amplitude\n",
    "    \n",
    "    # Hard-coded elsewhere:\n",
    "    L = 0.75*dx\n",
    "    \n",
    "    Q = np.zeros((ny*nx, ny*nx))\n",
    "    for a_y in range(ny):\n",
    "        for a_x in range(nx):\n",
    "            j = a_y*nx + a_x\n",
    "            for b_y in range(a_y-cutoff, a_y+cutoff+1):\n",
    "                if b_y < 0:    \n",
    "                     b_y = b_y + ny\n",
    "                if b_y > ny-1: \n",
    "                    b_y = b_y - ny\n",
    "                for b_x in range(a_x-cutoff, a_x+cutoff+1):\n",
    "                    if b_x < 0:\n",
    "                        b_x = b_x + nx\n",
    "                    if b_x > nx-1: \n",
    "                        b_x = b_x - nx\n",
    "                    i = b_y*nx + b_x\n",
    "                    Q[j, i] = _periodic_SOAR_Q(a_x, a_y, b_x, b_y, dx, dy, nx, ny, q0, L)\n",
    "    return Q\n",
    "\n",
    "\n",
    "def _createUGBmatrix(ensemble, nx=None, ny=None):\n",
    "    if nx is None:\n",
    "        nx = ensemble.nx\n",
    "    if ny is None:\n",
    "        ny = ensemble.ny\n",
    "    dx = ensemble.dx\n",
    "    dy = ensemble.dy\n",
    "    g  = ensemble.g\n",
    "    H  = np.max(ensemble.base_H)\n",
    "    f  = ensemble.f\n",
    "    \n",
    "    \n",
    "    newCorrect = True\n",
    "    print \"newCorrect: \", newCorrect\n",
    "    \n",
    "    I = np.eye(nx*ny)\n",
    "    A_hu = np.zeros((ny*nx, ny*nx))\n",
    "    A_hv = np.zeros((ny*nx, ny*nx))\n",
    "    for a_y in range(ny):\n",
    "        for a_x in range(nx):\n",
    "            if newCorrect:\n",
    "                j = a_y*nx + a_x\n",
    "                \n",
    "                # geo balance for hu:\n",
    "                i = (a_y+1)*nx + a_x\n",
    "                if a_y == ny-1:\n",
    "                    i = 0*nx + a_x\n",
    "                A_hu[j,i] = 1.0\n",
    "                i = (a_y-1)*nx + a_x\n",
    "                if a_y == 0:\n",
    "                    i = (ny-1)*nx + a_x\n",
    "                A_hu[j,i] = -1.0\n",
    "\n",
    "                # geo balance for hv:\n",
    "                i = a_y*nx + a_x + 1\n",
    "                if a_x == nx-1:\n",
    "                    i = a_y*nx + 0\n",
    "                A_hv[j,i] = 1.0\n",
    "\n",
    "                i = a_y*nx + a_x - 1\n",
    "                if a_x == 0:\n",
    "                    i = a_y*nx + nx - 1\n",
    "                A_hv[j,i] = -1.0\n",
    "            \n",
    "            else:\n",
    "                i = a_y*nx + a_x\n",
    "\n",
    "                # geo balance for hu:\n",
    "                j = (a_y+1)*nx + a_x\n",
    "                if a_y == ny-1:\n",
    "                    j = 0*nx + a_x\n",
    "                A_hu[j,i] = 1.0\n",
    "                j = (a_y-1)*nx + a_x\n",
    "                if a_y == 0:\n",
    "                    j = (ny-1)*nx + a_x\n",
    "                A_hu[j,i] = -1.0\n",
    "\n",
    "                # geo balance for hv:\n",
    "                j = a_y*nx + a_x + 1\n",
    "                if a_x == nx-1:\n",
    "                    j = a_y*nx + 0\n",
    "                A_hv[j,i] = 1.0\n",
    "\n",
    "                j = a_y*nx + a_x - 1\n",
    "                if a_x == 0:\n",
    "                    j = a_y*nx + nx - 1\n",
    "                A_hv[j,i] = -1.0\n",
    "            \n",
    "    A_hu *= -g*H/(f*2*dy)\n",
    "    A_hv *=  g*H/(f*2*dx)\n",
    "            \n",
    "    return np.bmat([[I], [A_hu], [A_hv]])\n",
    "\n",
    "def _createMatrixH(nx, ny, pos_x, pos_y):\n",
    "    H = np.zeros((2, 3*nx*ny))\n",
    "    index = pos_y*nx + pos_x\n",
    "    H[0, 1*nx*ny + index] = 1\n",
    "    H[1, 2*nx*ny + index] = 1\n",
    "    return H\n",
    "\n",
    "def generateLocaleSVDforP(ensemble, S, debug=False):\n",
    "    \"\"\"\n",
    "    Generates the local square root of the SVD-block needed for P^1/2.\n",
    "    \n",
    "    Finding:   U*Sigma*V^H = I - Q*U_GB^T*H^T*S*H*U_GB*Q\n",
    "    Returning: U*sqrt(Sigma)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Since the structure of the SVD-block is the same for any drifter position, we build the block\n",
    "    # on a 7x7 domain with the observation in the middle cell\n",
    "    local_nx = 7\n",
    "    local_ny = 7\n",
    "    pos_x = 3\n",
    "    pos_y = 3\n",
    "    \n",
    "    # Create the matrices needed\n",
    "    H      = _createMatrixH(local_nx, local_ny, pos_x, pos_y)\n",
    "    Q_soar = _createCutoffSOARMatrixQ(ensemble, nx=local_nx, ny=local_ny)\n",
    "    U_GB   = _createUGBmatrix(ensemble, nx=local_nx, ny=local_ny)\n",
    "    \n",
    "    UQ = np.dot(U_GB, Q_soar)\n",
    "    HUQ = np.dot(H, UQ)\n",
    "    SHUQ = np.dot(S, HUQ)\n",
    "    HTSHUQ = np.dot(H.transpose(), SHUQ)\n",
    "    UTHTSHUQ = np.dot(U_GB.transpose(), HTSHUQ)\n",
    "    QUTHTSHUQ = np.dot(Q_soar, UTHTSHUQ)\n",
    "    \n",
    "    svd_input = np.eye(local_nx*local_nx) - QUTHTSHUQ\n",
    "    \n",
    "    u, s, vh = np.linalg.svd(svd_input, full_matrices=True)\n",
    "    \n",
    "    if debug:\n",
    "        SVD_prod = np.dot(u, np.dot(np.diag(s), vh))\n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "        plt.imshow(SVD_prod, interpolation=\"None\")\n",
    "        plt.title(\"SVD_prod\")\n",
    "        plt.colorbar()\n",
    "        \n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "        plt.imshow(SVD_prod - np.eye(49), interpolation=\"None\")\n",
    "        plt.title(\"SVD_prod - I\")\n",
    "        plt.colorbar()\n",
    "        \n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "        plt.imshow(u, interpolation=\"None\")\n",
    "        plt.title(\"u\")\n",
    "        plt.colorbar()\n",
    "        \n",
    "        \n",
    "    return np.dot(u, np.diag(np.sqrt(s)))\n",
    "    \n",
    "debug = False\n",
    "local_sqrt_term = generateLocaleSVDforP(ensemble, S, debug=True)\n",
    "print \"local_sqrt_term.shape: \", local_sqrt_term.shape\n",
    "if debug:\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    plt.imshow(local_sqrt_term, interpolation=\"None\")\n",
    "    plt.title(\"local_sqrt_term\")\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if 'noise' in globals():\n",
    "    noise.cleanUp()\n",
    "    \n",
    "#noise = OceanStateNoise.OceanStateNoise.fromsim(ensemble.particles[0], \n",
    "#                                                soar_q0=ensemble.small_scale_perturbation_amplitude)\n",
    "\n",
    "# This is the function that needs to be implemented on GPU\n",
    "def _apply_local_SVD_to_global_xi(local_sqrt_term, global_xi, nx, ny, pos_x, pos_y):\n",
    "    \"\"\"\n",
    "    Despite the bad name, this is a good function!\n",
    "    \n",
    "    It takes as input:\n",
    "     - local sqrt(SVD) as U*sqrt(Sigma) in a (49, 49) buffer \n",
    "     - the global xi stored in a (ny, nx) buffer\n",
    "     \n",
    "    The second buffer is modified so that xi = U*sqrt(Sigma)*xi\n",
    "    \n",
    "    Note that we have to make a copy of xi so that we don't read already updated values.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Copy the result (representing the multiplication with I)\n",
    "    read_global_xi = global_xi.copy()\n",
    "    \n",
    "    # Read the non-zero structure from tildeP to tildeP_block\n",
    "    for loc_y_j in range(7):\n",
    "        global_y_j = pos_y - 3 + loc_y_j\n",
    "        for loc_x_j in range(7):\n",
    "            global_x_j = pos_x - 3 + loc_x_j\n",
    "            \n",
    "            global_j = global_y_j*nx + global_x_j\n",
    "            local_j = loc_y_j*7 + loc_x_j\n",
    "            \n",
    "            #loc_vec[local_j] = glob_vec[global_j]\n",
    "            \n",
    "            xi_j = 0.0\n",
    "            for loc_y_i in range(7):\n",
    "                global_y_i = pos_y - 3 + loc_y_i\n",
    "                for loc_x_i in range(7):\n",
    "                    global_x_i = pos_x - 3 + loc_x_i\n",
    "                    \n",
    "                    global_i = global_y_i*nx + global_x_i\n",
    "                    local_i = loc_y_i*7 + loc_x_i\n",
    "                    \n",
    "                    xi_j += local_sqrt_term[local_j, local_i]*read_global_xi[global_y_i, global_x_i]\n",
    "            \n",
    "            global_xi[global_y_j, global_x_j] = xi_j\n",
    "\n",
    "\n",
    "def drawFromP(S, local_SVD_sqrt, sim, drifter_pos, const_H, debug=False):\n",
    "    nx, ny = sim.nx, sim.ny\n",
    "    \n",
    "    # 0) Find the cell index for the noise.random_numbers_host buffer.\n",
    "    # This buffer has no ghost cells.\n",
    "    cell_id_x = int(np.floor(drifter_pos[0]/sim.dx))\n",
    "    cell_id_y = int(np.floor(drifter_pos[1]/sim.dy))\n",
    "    \n",
    "    # 1) Draw \\tilde{\\xi} \\sim N(0, I)\n",
    "    sim.small_scale_model_error.generateNormalDistributionCPU()\n",
    "    if debug: print \"noise shape: \", sim.small_scale_model_error.random_numbers_host.shape    \n",
    "    \n",
    "    # 1.5) Find gamma, which is needed by step 3\n",
    "    gamma = np.sum(sim.small_scale_model_error.random_numbers_host **2)\n",
    "    if debug: print \"Gamma obtained from standard gaussian: \", gamma\n",
    "    \n",
    "    # 2) Apply the local sqrt(SVD)-term\n",
    "    _apply_local_SVD_to_global_xi(local_sqrt_term, sim.small_scale_model_error.random_numbers_host, nx, ny, cell_id_x, cell_id_y)\n",
    "    \n",
    "    # 3 and 4) Apply SOAR and geostrophic balance\n",
    "    H_mid = sim.downloadBathymetry()[0]\n",
    "    p_eta, p_hu, p_hv = sim.small_scale_model_error._obtainOceanPerturbations_CPU(H_mid, sim.f, sim.coriolis_beta, sim.g)\n",
    "    \n",
    "    #gamma_from_p = np.sum(p_eta[1:-1, 1:-1]**2) + np.sum(p_hu**2) + np.sum(p_hv**2)\n",
    "    #if debug: print \"Gamma obtained from P^1/2 xi: \", gamma_from_p\n",
    "    \n",
    "    return p_eta[1:-1, 1:-1], p_hu, p_hv, gamma\n",
    "    \n",
    "    \n",
    "def drawFromQ(S, drifter_pos, sim, Hi, debug=False):\n",
    "    nx, ny = sim.nx, sim.ny\n",
    "    \n",
    "    # 1) Allocate memory and prepare stuff\n",
    "        \n",
    "    # Allocate data\n",
    "    q_eta = np.zeros((ny, nx))\n",
    "    q_hu  = np.zeros((ny, nx))\n",
    "    q_hv  = np.zeros((ny, nx))\n",
    "    \n",
    "    sim.small_scale_model_error.perturbOceanStateCPU(q_eta, q_hu, q_hv, Hi, sim.f)\n",
    "    \n",
    "    return q_eta, q_hu, q_hv\n",
    "    \n",
    "    \n",
    "observed_drifter_position = ensemble.observeTrueDrifters()\n",
    "print observed_drifter_position\n",
    "\n",
    "xi = [None]*ensemble.getNumParticles()\n",
    "\n",
    "\n",
    "useQinsteadofP = False\n",
    "\n",
    "if useQinsteadofP:\n",
    "    for p in range(ensemble.getNumParticles()):\n",
    "        q_eta, q_hu, q_hv = drawFromQ(S,  observed_drifter_position, \\\n",
    "                                      ensemble.particles[p], Hi, debug=False)\n",
    "        xi[p] = [q_eta, q_hu, q_hv, q_x, q_y]\n",
    "        print \"Done with \" + str(p)\n",
    "        if p == 0:\n",
    "            showMatrices(q_eta, q_hu, \"Drawing from Q\", q_hv)\n",
    "else:\n",
    "    for p in range(ensemble.getNumParticles()):\n",
    "        #for p in range(1):\n",
    "        p_eta, p_hu, p_hv, gamma = drawFromP(S, local_sqrt_term, ensemble.particles[p], \n",
    "                                             observed_drifter_position, waterDepth, debug=True)\n",
    "        xi[p] = [p_eta, p_hu, p_hv, gamma]\n",
    "        if p == 0:\n",
    "            showMatrices(p_eta, p_hu, \"Drawing from P\", p_hv)\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print sim.small_scale_model_error.soar_q0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for p in range(ensemble.getNumParticles()):\n",
    "    showMatrices(xi[p][0], xi[p][1], \"particle \" + str(p), xi[p][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "\n",
    "We now use the samples of $\\xi$ to push each particle towards the observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def implicitEquation(alpha, gamma, Nx, a):\n",
    "    return (alpha-1.0)*gamma - Nx*np.log(alpha) + a\n",
    "\n",
    "def pushParticleTowardsObservation(sim, S, \\\n",
    "                                   observed_drifter_position, innovation, xi, gamma, \n",
    "                                   const_H, \n",
    "                                   target_weight, w_rest, debug=True, returnKalmanGainTerm=False):\n",
    "    # Following the 3rd step of the IEWPF algorithm\n",
    "    \n",
    "    if debug: print \"(nx, ny, dx, dy): \", (sim.nx, sim.ny, sim.dx, sim.dy)\n",
    "    if debug: print \"observed_drifter_position: \", observed_drifter_position\n",
    "    if debug: print \"innovation:  \", innovation\n",
    "    if debug: print \"target_weight: \", target_weight\n",
    "\n",
    "        \n",
    "    # 0) Define constants/buffers etc\n",
    "    geo_balance_const = sim.g*const_H/sim.f\n",
    "    Nx = nx*ny*3.0 # State dimension\n",
    "    \n",
    "    # 0.1) Find the cell index assuming no ghost cells\n",
    "    cell_id_x = int(np.floor(observed_drifter_position[0]/sim.dx))\n",
    "    cell_id_y = int(np.floor(observed_drifter_position[1]/sim.dy))\n",
    "    if debug: print \"(cell_id_x, cell_id_y): \", (cell_id_x, cell_id_y)\n",
    "    \n",
    "    # 1) Solve linear problem\n",
    "    e = np.dot(S, innovation)\n",
    "    if debug: print \"e: \", e\n",
    "    \n",
    "    # 2) K = QH^T e = U_GB Q^{1/2} Q^{1/2} U_GB^T  H^T e\n",
    "    #    Obtain the Kalman gain\n",
    "    # 2.1) U_GB^T H^T e\n",
    "    # 2.1.1) H^T: The transpose of the observation operator now maps the velocity at the \n",
    "    #        drifter position to the complete state vector:\n",
    "    #        H^T [hu(posx, posy), hv(posx, posy)] = [zeros_eta, 0 0 hu(posx, posy) 0 0, 0 0 hv(posx, posy) 0 0]\n",
    "    \n",
    "    # 2.1.2) U_GB^T: map out to laplacian stencil\n",
    "    local_huhv = np.zeros(4) # representing [north, east, south, west] positions from \n",
    "    north_east_south_west_index = [[4,3,0], [3,4,1], [2,3,2], [3,2,3]] #[[y-index-eta, x-index-eta, index-local_eta_soar]]\n",
    "    # the x-component of the innovation spreads to north and south\n",
    "    local_huhv[0] = -e[0,0]*geo_balance_const/(2*sim.dy) # north \n",
    "    local_huhv[2] =  e[0,0]*geo_balance_const/(2*sim.dy) # south\n",
    "    # the y-component of the innovation spreads to east and west\n",
    "    local_huhv[1] =  e[0,1]*geo_balance_const/(2*sim.dx) # east\n",
    "    local_huhv[3] = -e[0,1]*geo_balance_const/(2*sim.dx) # west\n",
    "    \n",
    "    # 2.1.3) Q^{1/2}:\n",
    "    local_eta = np.zeros((7,7))\n",
    "    for j,i,soar_res_index in north_east_south_west_index:\n",
    "        if debug: print (j,i), soar_res_index\n",
    "        for b in range(j-2, j+3):\n",
    "            for a in range(i-2, i+3):\n",
    "                local_eta[b,a] += local_huhv[soar_res_index]*SOAR_Q(a, b, i, j, sim.dx, sim.dy, \n",
    "                                                                    sim.small_scale_model_error.soar_q0, \n",
    "                                                                    sim.small_scale_model_error.soar_L)\n",
    "    if debug: showMatrices(local_eta, local_eta, \"local $\\eta$ from global $\\eta$\")\n",
    "           \n",
    "    # 2.2) Apply U_GB Q^{1/2} to the result\n",
    "    # 2.2.1)  Easiest way: map local_eta to a global K_eta_tmp buffer\n",
    "    K_eta_tmp = np.zeros((sim.ny, sim.nx))\n",
    "    if debug: print \"K_eta_tmp.shape\",  K_eta_tmp.shape\n",
    "    for j in range(7):\n",
    "        j_global = (cell_id_y-3+j+sim.ny)%sim.ny \n",
    "        for i in range(7):\n",
    "            i_global = (cell_id_x-3+i+sim.nx)%sim.nx \n",
    "            K_eta_tmp[j_global, i_global] += local_eta[j,i]\n",
    "            #K_eta_tmp[j_global, i_global] += 10000000*local_eta[j,i]\n",
    "    if debug: showMatrices(K_eta_tmp, local_eta, \"global K_eta from local K_eta, halfway in the calc.\")\n",
    "               \n",
    "    # 2.2.2) Use K_eta_tmp as the noise.random_numbers_host\n",
    "    sim.small_scale_model_error.random_numbers_host = K_eta_tmp\n",
    "    \n",
    "    # 2.2.3) Apply soar + geo-balance\n",
    "    K_eta , K_hu, K_hv = sim.small_scale_model_error._obtainOceanPerturbations_CPU(ensemble.base_H, sim.f, sim.coriolis_beta, sim.g)\n",
    "    K_eta = K_eta[1:-1, 1:-1]\n",
    "    if debug: showMatrices(K_eta, K_hu, \"Kalman gain\", K_hv)\n",
    "    \n",
    "    if returnKalmanGainTerm:\n",
    "        return K_eta, K_hu, K_hv\n",
    "    \n",
    "    # 3) Obtain phi = d^T * e\n",
    "    phi = innovation[0]*e[0,0] + innovation[1]*e[0,1]\n",
    "    if debug: print \"phi: \", phi\n",
    "        \n",
    "    # 4) Obtain x_a\n",
    "    nudged_eta, nudged_hu, nudged_hv = sim.download(interior_domain_only=True)\n",
    "    original_hu = nudged_hu[cell_id_y, cell_id_x]\n",
    "    original_hv = nudged_hv[cell_id_y, cell_id_x]\n",
    "    if debug: showMatrices(nudged_eta, nudged_hu, \"$M(x)$\", nudged_hv)\n",
    "    nudged_eta += K_eta\n",
    "    nudged_hu += K_hu\n",
    "    nudged_hv += K_hv\n",
    "    if debug: print \"Shapes of nudged vars: \", nudged_eta.shape, nudged_hu.shape, nudged_hv.shape\n",
    "    if debug: showMatrices(nudged_eta, nudged_hu, \"$x_a = M(x) + K$\", nudged_hv)\n",
    "        \n",
    "    # 5) obtain gamma\n",
    "    if debug: print \"Shapes of xi: \", xi[0].shape, xi[1].shape, xi[2].shape\n",
    "    #gamma = 0.0\n",
    "    #for field in range(3):\n",
    "    #    for j in range(ny):\n",
    "    #        for i in range(nx):\n",
    "    #            gamma += xi[field][j,i]*xi[field][j,i]\n",
    "    if debug: print \"gamma: \", gamma\n",
    "    if debug: print \"Nx: \", Nx\n",
    "    if debug: print \"w_rest: \", w_rest\n",
    "    if debug: print \"target_weight: \", target_weight\n",
    "        \n",
    "    # 6) Find a\n",
    "    a = phi - w_rest + target_weight\n",
    "    if debug: print \"a = phi - w_rest + target_weight: \", a\n",
    "            \n",
    "    # 7) Solving the Lambert W function\n",
    "    #alpha = 10000\n",
    "    lambert_W_arg = -(gamma/Nx)*np.exp(a/Nx)*np.exp(-gamma/Nx)\n",
    "    alpha_min1 = -(Nx/gamma)*np.real(lambertw(lambert_W_arg, k=-1))\n",
    "    alpha_zero = -(Nx/gamma)*np.real(lambertw(lambert_W_arg))\n",
    "    if debug: print \"Check a against the Lambert W requirement: \", a, \" < \", - Nx + gamma - Nx*np.log(gamma/Nx), \" = \", a <  - Nx + gamma - Nx*np.log(gamma/Nx)\n",
    "    if debug: print \"-e^-1 < z < 0 : \", -1.0/np.exp(1), \" < \", lambert_W_arg, \" < \", 0, \" = \", \\\n",
    "        (-1.0/np.exp(1) < lambert_W_arg, lambert_W_arg < 0)\n",
    "    if debug: print \"Obtained (alpha k=-1, alpha k=0): \", (alpha_min1, alpha_zero)\n",
    "    if debug: print \"The two branches from Lambert W: \", (lambertw(lambert_W_arg), lambertw(lambert_W_arg, k=-1))\n",
    "    if debug: print \"The two branches from Lambert W: \", (np.real(lambertw(lambert_W_arg)), np.real(lambertw(lambert_W_arg, k=-1)))\n",
    "    \n",
    "    alpha = alpha_zero\n",
    "    if lambert_W_arg > (-1.0/np.exp(1)) :\n",
    "        alpha_u = np.random.rand()\n",
    "        if alpha_u < 0.5:\n",
    "            alpha = alpha_min1\n",
    "            if debug: print \"Drew alpha from -1-branch\"\n",
    "    else:\n",
    "        print \"!!!!!!!!!!!!\"\n",
    "        print \"BAD BAD ARGUMENT TO LAMBERT W\"\n",
    "        print \"Obtained (alpha k=0, alpha k=-1): \", (alpha_zero, alpha_min1)\n",
    "        print \"!!!!!!!!!!!!\"\n",
    "    #if debug: print \"Drawing random number alpha_u: \", alpha_u\n",
    "    #oldDebug = debug\n",
    "    #debug = True\n",
    "    if debug: print \"--------------------------------------\"\n",
    "    if debug: print \"Obtained (lambert_ans k=0, lambert_ans k=-1): \", (lambertw(lambert_W_arg), lambertw(lambert_W_arg, k=-1))\n",
    "    if debug: print \"Obtained (alpha k=0, alpha k=-1): \", (alpha_zero, alpha_min1)\n",
    "    if debug: print \"Checking implicit equation with alpha (k=0, k=-1): \", \\\n",
    "        (implicitEquation(alpha_zero, gamma, Nx, a), implicitEquation(alpha_min1, gamma, Nx, a))\n",
    "    #if debug: print \"Chose alpha = \", alpha\n",
    "    #if debug: print \"The implicit equation looked like: \\n\\t\" + \\\n",
    "    #    \"(alpha - 1)\"+str(gamma)+\" - \" + str(Nx) + \"log(alpha) + \" + str(a) + \" = 0\"\n",
    "    #if debug: print \"Parameters: (gamma, Nx, aj)\", (gamma, Nx, a)\n",
    "    \n",
    "    alpha = np.sqrt(alpha)\n",
    "    if debug: print \"alpha = np.sqrt(alpha) ->  \", alpha\n",
    "    if debug: print \"--------------------------------------\"\n",
    "    #debug = oldDebug\n",
    "    \n",
    "    # 7.2) alpha*xi\n",
    "    if debug: showMatrices(alpha*xi[0], alpha*xi[1], \"alpha * xi\", alpha*xi[2])\n",
    "    \n",
    "    # 8) Final nudge!\n",
    "    nudged_eta += alpha*xi[0]\n",
    "    nudged_hu += alpha*xi[1]\n",
    "    nudged_hv += alpha*xi[2]\n",
    "    if debug: showMatrices(nudged_eta, nudged_hu, \"Nudged field\", nudged_hv)\n",
    "    if debug: print \"Original velocity under drifter (hu, hv): \", (original_hu, original_hu)\n",
    "    final_hu = nudged_hu[cell_id_y, cell_id_x]\n",
    "    final_hv = nudged_hv[cell_id_y, cell_id_x]\n",
    "    if debug: print \"Final nudged velocity under drifter (hu, hv): \", (final_hu, final_hv)\n",
    "    if debug: print \"Diff original - nudged: \", (original_hu-final_hu, original_hu-final_hv)\n",
    "                \n",
    "    return nudged_eta, nudged_hu, nudged_hv\n",
    "\n",
    "print \"(ensemble.ny, ensemble.nx)\", (ensemble.ny, ensemble.nx)\n",
    "print \"target_weight: \", target_weight\n",
    "print \"observation of true state: \", ensemble.observeTrueState()\n",
    "innovations = ensemble.getInnovations()\n",
    "w_rest = -np.log(ensemble.getGaussianWeight())\n",
    "print w_rest\n",
    "for p in range(ensemble.getNumParticles()):\n",
    "    print \" \"\n",
    "    n_eta, n_hu, n_hv = pushParticleTowardsObservation(ensemble.particles[p], S, \\\n",
    "                                                       observed_drifter_position, innovations[p], xi[p], xi[p][3], \n",
    "                                                       waterDepth, \n",
    "                                                       target_weight, w_rest[p], debug=(p==-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def expand_to_periodic_boundaries(interior, ghostcells):\n",
    "    if ghostcells == 0:\n",
    "        return interior\n",
    "    (ny, nx) = interior.shape\n",
    "    \n",
    "    nx_halo = nx + 2*ghostcells\n",
    "    ny_halo = ny + 2*ghostcells\n",
    "    newBuf = np.zeros((ny_halo, nx_halo))\n",
    "    newBuf[ghostcells:-ghostcells, ghostcells:-ghostcells] = interior \n",
    "    for g in range(ghostcells):\n",
    "        newBuf[g, :] = newBuf[ny_halo - 2*ghostcells + g, :]\n",
    "        #newBuf[ny_halo - 2*ghostcells + g, :] *=0\n",
    "        newBuf[ny_halo - 1 - g, :] = newBuf[2*ghostcells - 1 - g, :]\n",
    "        #newBuf[2*ghostcells - 1 - g, :] *=0\n",
    "    for g in range(ghostcells):\n",
    "        newBuf[:, g] = newBuf[:, nx_halo - 2*ghostcells + g]\n",
    "        newBuf[:, nx_halo - 1 - g] = newBuf[:, 2*ghostcells - 1 - g]\n",
    "    return newBuf\n",
    "    \n",
    "test = np.zeros((30, 20))\n",
    "for y in range(30):\n",
    "    for x in range(20):\n",
    "        test[y, x] = np.sqrt((x - 9.5)**2 + (y - 14.5)**2)\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(test, interpolation=\"None\")\n",
    "test = expand_to_periodic_boundaries(test, 2)\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(test, interpolation=\"None\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing IEWPF\n",
    "\n",
    "Here, we make a test of the entire IEWPF algorithm applied to a suitable test case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DEFINE PARAMETERS\n",
    "\n",
    "#Coriolis well balanced reconstruction scheme\n",
    "nx = 40\n",
    "ny = 40\n",
    "\n",
    "dx = 4.0\n",
    "dy = 4.0\n",
    "\n",
    "dt = 0.05*3\n",
    "g = 9.81\n",
    "r = 0.0\n",
    "\n",
    "f = 0.05\n",
    "beta = 0.0\n",
    "\n",
    "ghosts = np.array([2,2,2,2]) # north, east, south, west\n",
    "validDomain = np.array([2,2,2,2])\n",
    "boundaryConditions = Common.BoundaryConditions(2,2,2,2)\n",
    "\n",
    "# Define which cell index which has lower left corner as position (0,0)\n",
    "x_zero_ref = 2\n",
    "y_zero_ref = 2\n",
    "\n",
    "dataShape = (ny + ghosts[0]+ghosts[2], \n",
    "             nx + ghosts[1]+ghosts[3])\n",
    "dataShapeHi = (ny + ghosts[0]+ghosts[2]+1, \n",
    "             nx + ghosts[1]+ghosts[3]+1)\n",
    "\n",
    "eta0 = np.zeros(dataShape, dtype=np.float32, order='C');\n",
    "eta0_extra = np.zeros(dataShape, dtype=np.float32, order='C')\n",
    "hv0 = np.zeros(dataShape, dtype=np.float32, order='C');\n",
    "hu0 = np.zeros(dataShape, dtype=np.float32, order='C');\n",
    "waterDepth = 1.0\n",
    "Hi = np.ones(dataShapeHi, dtype=np.float32, order='C')*waterDepth\n",
    "\n",
    "# Add disturbance:\n",
    "initOption = 3\n",
    "if initOption == 1:\n",
    "    # Original initial conditions\n",
    "    rel_grid_size = nx*1.0/dx\n",
    "    BC.addBump(eta0, nx, ny, dx, dy, 0.3, 0.5, 0.05*rel_grid_size, validDomain)\n",
    "    eta0 = eta0*0.3\n",
    "    BC.addBump(eta0, nx, ny, dx, dy, 0.7, 0.3, 0.10*rel_grid_size, validDomain)\n",
    "    eta0 = eta0*(-1.3)\n",
    "    BC.addBump(eta0, nx, ny, dx, dy, 0.15, 0.8, 0.03*rel_grid_size, validDomain)\n",
    "    eta0 = eta0*1.0\n",
    "    BC.addBump(eta0, nx, ny, dx, dy, 0.6, 0.75, 0.06*rel_grid_size, validDomain)\n",
    "    BC.addBump(eta0, nx, ny, dx, dy, 0.2, 0.2, 0.01*rel_grid_size, validDomain)\n",
    "    eta0 = eta0*(-0.03)\n",
    "    BC.addBump(eta0_extra, nx, ny, dx, dy, 0.5, 0.5, 0.4*rel_grid_size, validDomain)\n",
    "    eta0 = eta0 + 0.02*eta0_extra\n",
    "    BC.initializeBalancedVelocityField(eta0, Hi, hu0, hv0, f, beta, g, nx, ny, dx ,dy, ghosts)\n",
    "    eta0 = eta0*0.5\n",
    "elif initOption == 2:\n",
    "    # Initial conditions used for the SIR filter\n",
    "    rel_grid_size = nx*1.0/dx\n",
    "    BC.addBump(eta0, nx, ny, dx, dy, 0.3, 0.5, 0.05*rel_grid_size, validDomain)\n",
    "    eta0 = eta0*0.3\n",
    "    BC.addBump(eta0, nx, ny, dx, dy, 0.7, 0.3, 0.10*rel_grid_size, validDomain)\n",
    "    eta0 = eta0*(-1.3)\n",
    "    BC.addBump(eta0, nx, ny, dx, dy, 0.15, 0.8, 0.03*rel_grid_size, validDomain)\n",
    "    eta0 = eta0*1.0\n",
    "    BC.addBump(eta0, nx, ny, dx, dy, 0.6, 0.75, 0.06*rel_grid_size, validDomain)\n",
    "    BC.addBump(eta0, nx, ny, dx, dy, 0.2, 0.2, 0.01*rel_grid_size, validDomain)\n",
    "    eta0 = eta0*(-0.03)\n",
    "    BC.addBump(eta0_extra, nx, ny, dx, dy, 0.5, 0.5, 0.4*rel_grid_size, validDomain)\n",
    "    eta0 = eta0 + 0.02*eta0_extra\n",
    "    BC.initializeBalancedVelocityField(eta0, Hi, hu0, hv0, f, beta, g, nx, ny, dx ,dy, ghosts)\n",
    "    eta0 = eta0*0.5\n",
    "elif initOption == 3:\n",
    "    # Initial conditions random - see further down!\n",
    "    pass\n",
    "    \n",
    "\n",
    "if 'sim' in globals():\n",
    "    sim.cleanUp()\n",
    "if 'ensemble' in globals():\n",
    "    ensemble.cleanUp()\n",
    "    \n",
    "q0 = 0.5*dt*f/(g*waterDepth)\n",
    "print \"q0: \", q0\n",
    "print \"[f, g, H, dt]\", [f, g, waterDepth, dt]\n",
    "print \"f/gH: \", f/(g*waterDepth)\n",
    "print \"gH/f: \", g*waterDepth/f\n",
    "\n",
    "reload(CDKLM16)\n",
    "reload(BaseOceanStateEnsemble)\n",
    "reload(OceanNoiseEnsemble)\n",
    "reload(PlotHelper)\n",
    "reload(dautils)\n",
    "sim = CDKLM16.CDKLM16(cl_ctx, eta0, hu0, hv0, Hi, \\\n",
    "                      nx, ny, dx, dy, dt, g, f, r, \\\n",
    "                      boundary_conditions=boundaryConditions, \\\n",
    "                      write_netcdf=False, \\\n",
    "                      small_scale_perturbation=True, \\\n",
    "                      small_scale_perturbation_amplitude=q0)\n",
    "if initOption == 3:\n",
    "    sim.perturbState(q0_scale=50)\n",
    "    \n",
    "ensemble_size = 30\n",
    "\n",
    "ensemble = OceanNoiseEnsemble.OceanNoiseEnsemble(ensemble_size, cl_ctx,  \n",
    "                                                 observation_type=dautils.ObservationType.DirectUnderlyingFlow)\n",
    "ensemble.setGridInfoFromSim(sim)\n",
    "ensemble.setStochasticVariables(#observation_variance_factor=2.0,\n",
    "                                observation_variance = 0.01**2,\n",
    "                                small_scale_perturbation_amplitude=q0)\n",
    "                                #initialization_variance_factor_ocean_field=50)\n",
    "ensemble.init()\n",
    "\n",
    "max_dt = ensemble.findLargestPossibleTimeStep()\n",
    "print \"max_dt: \", max_dt\n",
    "\n",
    "S = createS(ensemble, waterDepth)\n",
    "local_SVD_block = generateLocaleSVDforP(ensemble, S)\n",
    "infoPlots = []\n",
    "debug=False\n",
    "\n",
    "fig = plt.figure()\n",
    "plotter = PlotHelper.EnsembleAnimator(fig, ensemble, trueStateOnly=False)\n",
    "\n",
    "def keepPlot(ensemble, infoPlots, it, stage):\n",
    "    title = \"it=\" + str(it) + \" before IEWPF\"\n",
    "    if stage == 2:\n",
    "        title = \"it=\" + str(it) + \" during IEWPF (with deterministic step)\"\n",
    "    elif stage == 3:\n",
    "        title = \"it=\" + str(it) + \" after IEWPF\"\n",
    "    infoFig = ensemble.plotDistanceInfo(title=title, printInfo=False)\n",
    "    plt.close(infoFig)\n",
    "    infoPlots.append(infoFig)\n",
    "    \n",
    "def iewpf(ensemble, infoPlots, it):\n",
    "    \n",
    "    # Step -1: Deterministic step\n",
    "    t = ensemble.step_truth(dt, stochastic=True)\n",
    "    \n",
    "    # Step 0: Obtain distances\n",
    "    observed_drifter_position = ensemble.observeTrueDrifters()\n",
    "    innovations = ensemble.getInnovations()\n",
    "    #w_rest = -np.log(ensemble.getGaussianWeight())\n",
    "    w_rest = -np.log(1.0/ensemble.getNumParticles())*np.ones(ensemble.getNumParticles())\n",
    "    t = ensemble.step_particles(dt, stochastic=False)\n",
    "    \n",
    "    # save plot halfway\n",
    "    keepPlot(ensemble, infoPlots, it, 1)\n",
    "    \n",
    "    # Step 1: Find maximum weight\n",
    "    target_weight = obtainTargetWeight(ensemble, S, w_rest)\n",
    "    #print \"WWWWWWWWWWWWWWW\"\n",
    "    #print \"Target weight: \", target_weight\n",
    "    #print \"-log(target_weight): \", -np.log(target_weight)\n",
    "    #print \"exp(-target_weight): \", np.exp(-target_weight)\n",
    "    #print \"1/Ne: \", 1.0/ensemble.getNumParticles()\n",
    "    #print \"WWWWWWWWWWWWWWW\"\n",
    "    \n",
    "    \n",
    "    for p in range(ensemble.getNumParticles()):\n",
    "\n",
    "        # Step 2: Sample xi \u00cc\u0192 N(0, P)\n",
    "        p_eta, p_hu, p_hv, gamma = drawFromP(S, local_SVD_block, ensemble.particles[p], \n",
    "                                             observed_drifter_position, waterDepth, debug=False)\n",
    "        xi = [p_eta, p_hu, p_hv] \n",
    "\n",
    "        # Step 3: Pull particles towards observation\n",
    "        #w_rest[p] = 0.0\n",
    "        new_eta, new_hu, new_hv = pushParticleTowardsObservation(ensemble.particles[p], S, \\\n",
    "                                                                 observed_drifter_position, \n",
    "                                                                 innovations[p], xi, \n",
    "                                                                 gamma,\n",
    "                                                                 waterDepth, target_weight, \n",
    "                                                                 w_rest[p], False)\n",
    "        new_eta = expand_to_periodic_boundaries(new_eta, 2)\n",
    "        new_hu  = expand_to_periodic_boundaries(new_hu,  2)\n",
    "        new_hv  = expand_to_periodic_boundaries(new_hv,  2)\n",
    "        ensemble.particles[p].upload(new_eta, new_hu, new_hv)\n",
    "        #ensemble.particles[p].drifters.setDrifterPositions(newPos)\n",
    "        \n",
    "    # save plot after\n",
    "    keepPlot(ensemble, infoPlots, it, 3)\n",
    "\n",
    "\n",
    "T = 13\n",
    "sub_t = 10*dt\n",
    "#observation_iterations = [4, 8, 12, 16]\n",
    "observation_iterations = range(1, 25, 2)\n",
    "def animate(i):\n",
    "    if (i>0):\n",
    "        t = ensemble.step(sub_t)\n",
    "    else:\n",
    "        t = 0.0\n",
    "\n",
    "    for oi in observation_iterations:\n",
    "        if i == oi:\n",
    "            print \"Enter IEWPF\"\n",
    "            max_dt = ensemble.findLargestPossibleTimeStep()\n",
    "            print \"max_dt: \", max_dt\n",
    "            iewpf(ensemble, infoPlots, i)\n",
    "            #keepPlot(ensemble, infoPlots, i, 1)\n",
    "            print \"Successful IEWPF (hopefully)\"\n",
    "        \n",
    "    plotter.plot(ensemble);\n",
    "\n",
    "    fig.suptitle(\"Ensemble = \" + \"{:04.0f}\".format(t) + \" s\", fontsize=18)\n",
    "\n",
    "    if (i%5 == 0):\n",
    "        print \"{:03.0f}\".format(100*i / T) + \" % => t=\" + str(t)\n",
    "        #if i != 0: \n",
    "        #    ensemble.printMaxOceanStates()\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, range(T), interval=100)\n",
    "plt.close(anim._fig)\n",
    "anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def show_figures(figs):\n",
    "    for f in figs:\n",
    "        dummy = plt.figure()\n",
    "        new_manager = dummy.canvas.manager\n",
    "        new_manager.canvas.figure = f\n",
    "        f.set_canvas(new_manager.canvas)\n",
    "        filename= f._suptitle.get_text().replace(\" \", \"_\").replace(\"=_\", \"\") + \".png\"\n",
    "        #plt.savefig(filename)\n",
    "show_figures(infoPlots)\n",
    "fig = ensemble.plotDistanceInfo(title=\"Final ensemble\")\n",
    "ensemble.plotEnsemble()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Prototyping***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking that np.reshape works as expected\n",
    "\n",
    "Assume that it reshapes by [1,2,3,4] -> [[1,2], [3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_array = np.array(range(1,21))\n",
    "print test_array\n",
    "\n",
    "# Expect 4 rows, 5 columns\n",
    "test_matrix = np.reshape(test_array, (4,5))\n",
    "print test_matrix\n",
    "print \"test_matrix.shape\", test_matrix.shape\n",
    "print test_matrix[3,1], test_array[3*5+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking  $Q^{1/2} \\xi$ \n",
    "\n",
    "Checking that $Q^{1/2}\\xi$ is the same for the operations and the matrix multiplications.\n",
    "\n",
    "$$ Q^{1/2} \\xi = U_{GB} Q_{SOAR}^{1/2}\\xi$$\n",
    "\n",
    "\n",
    "The difference below comes from the fact that $U_{GB}$ actually depends on $\\eta$... In the stencil operation, we use that \n",
    "$$\\Delta hu_{i,j} = -\\frac{g (H_{i,j} + \\eta_{i,j})}{f}\\frac{\\eta_{i, j+1} - \\eta_{i, j-1}}{2 \\Delta y}, $$\n",
    "while the matrix is constructed based on \n",
    "$$\\Delta hu_{i,j} = -\\frac{g H_0}{f}\\frac{\\eta_{i, j+1} - \\eta_{i, j-1}}{2 \\Delta y}, $$\n",
    "assuming that $H(x,y) = H_0 + \\eta \\approx H_0$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if 'noise' in globals():\n",
    "    noise.cleanUp()\n",
    "reload(OceanStateNoise)\n",
    "\n",
    "NX = 6#nx\n",
    "NY = 6#ny\n",
    "noise = OceanStateNoise.OceanStateNoise(sim.cl_ctx, sim.cl_queue,\n",
    "                                        NX, NY, dx, dy,\n",
    "                                        Common.BoundaryConditions(2,2,2,2), False,\n",
    "                                        soar_q0=q0)\n",
    "\n",
    "\n",
    "xi_array = np.random.normal(size=NY*NX)\n",
    "#xi_array = np.ones(NY*NX)\n",
    "#xi_array = np.linspace(0, 10, NY*NX)\n",
    "def make_bump(xi, nx, ny):\n",
    "    for j in range(ny):\n",
    "        for i in range(nx):\n",
    "            xi_array[j*nx + i] = np.exp(-0.3*np.sqrt((j-ny/2)**2 + (i-nx/2)**2))\n",
    "#make_bump(xi_array, NX, NY)\n",
    "print \"xi_array.shape\", xi_array.shape\n",
    "xi_matrix = np.reshape(xi_array, (NY, NX))\n",
    "#xi_matrix = np.reshape(xi_array, (NY, NX)).transpose()\n",
    "#xi_array = np.reshape(xi_matrix, NX*NY)\n",
    "print \"xi_matrix.shape\", xi_matrix.shape\n",
    "print \"Hi.shape\", Hi.shape, \"Hi[4,4]: \", Hi[4,4]\n",
    "Hi_interior = Hi[2:-2, 2:-2]\n",
    "print \"Hi_interior.shape\", Hi_interior.shape\n",
    "print \"min-max Hi_interior\", (np.min(Hi_interior), np.max(Hi_interior))\n",
    "\n",
    "print \"------------- Starting CPU operations --------\"\n",
    "print \"noise.random_numbers_host.shape\", noise.random_numbers_host.shape\n",
    "noise.random_numbers_host = xi_matrix\n",
    "res_eta, res_hu, res_hv = noise._obtainOceanPerturbations_CPU(Hi_interior, sim.f,\n",
    "                                                              sim.coriolis_beta, sim.g)\n",
    "res_eta = res_eta[1:-1, 1:-1]\n",
    "showMatrices(res_eta, res_hu, \"Operations from CPU\", res_hv)\n",
    "\n",
    "print \"-------- Starting matrices -----------\"\n",
    "Q_soar = _createCutoffSOARMatrixQ(ensemble, nx=NX, ny=NY, cutoff=2)\n",
    "U_GB = _createUGBmatrix(ensemble, nx=NX, ny=NY)\n",
    "print \"Q_soar.shape\", Q_soar.shape\n",
    "print \"U_GB.shape\", U_GB.shape\n",
    "#fig = plt.figure(figsize=(6,6))\n",
    "#plt.imshow(_createUGBmatrix(ensemble, nx=4, ny=5), interpolation=\"None\")\n",
    "\n",
    "print \"xi_array.shape\", xi_array.shape\n",
    "#Qxi = xi_array #\n",
    "Qxi = np.dot(Q_soar, xi_array)\n",
    "print \"Qxi.shape\", Qxi.shape\n",
    "UQxi = np.dot(U_GB, Qxi)\n",
    "print \"UQxi.shape\", UQxi.shape\n",
    "\n",
    "res_eta_matrix = np.reshape(UQxi[0,       :  NX*NY], (NY, NX))\n",
    "res_hu_matrix  = np.reshape(UQxi[0,  NX*NY:2*NX*NY], (NY, NX))\n",
    "res_hv_matrix  = np.reshape(UQxi[0,2*NX*NY:       ], (NY, NX))\n",
    "showMatrices(res_eta_matrix, res_hu_matrix, \"Matrix operations\", res_hv_matrix)\n",
    "\n",
    "abs_diff_eta = np.abs(res_eta_matrix - res_eta)\n",
    "abs_diff_hu  = np.abs(res_hu_matrix  - res_hu )\n",
    "abs_diff_hv  = np.abs(res_hv_matrix  - res_hv )\n",
    "showMatrices(abs_diff_eta, abs_diff_hu, \"Absolute differences\", abs_diff_hv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking  $P^{1/2} \\xi$ \n",
    "\n",
    "Checking that $P^{1/2}\\xi$ is the same for the operations and the matrix multiplications.\n",
    "\n",
    "$$ Q^{1/2} \\xi = U_{GB} \\tilde{Q}^{1/2} U \\Sigma^{1/2} \\tilde{\\xi}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the Kalman gain term\n",
    "Comparing the Kalman gain term by finding it as operations, and by finding it through matrix operations.\n",
    "\n",
    "The Kalman gain is given by\n",
    "$$K = Q H^T S d,$$\n",
    "which boils down to\n",
    "$$ K = U_{GB} \\tilde{Q}^{1/2} \\tilde{Q}^{1/2} U_{GB}^T H^T S d$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "innovations = ensemble.getInnovations()\n",
    "print \"innovations.shape\", innovations.shape\n",
    "observed_drifter_position = ensemble.observeTrueState()[0:2]\n",
    "\n",
    "K_eta, K_hu, K_hv = pushParticleTowardsObservation(ensemble.particles[2], S, \\\n",
    "                                                   observed_drifter_position, innovations[2], \\\n",
    "                                                   xi[2], xi[2][3], \n",
    "                                                   waterDepth, \n",
    "                                                   target_weight, w_rest[2], debug=False, \\\n",
    "                                                   returnKalmanGainTerm=True)\n",
    "showMatrices(K_eta, K_hu, \"Kalman gains from operations\", K_hv)\n",
    "\n",
    "print \"----------- Starting matrix operatioins -----------------\"\n",
    "cell_id_x = int(np.floor(observed_drifter_position[0]/ensemble.dx))\n",
    "cell_id_y = int(np.floor(observed_drifter_position[1]/ensemble.dy))\n",
    "Q_soar = _createCutoffSOARMatrixQ(ensemble)\n",
    "U_GB = _createUGBmatrix(ensemble)\n",
    "H = _createMatrixH(nx, ny, cell_id_x, cell_id_y)\n",
    "\n",
    "print \"Q_soar.shape\", Q_soar.shape\n",
    "print \"U_GB.shape\", U_GB.shape\n",
    "print \"H.shape\", H.shape\n",
    "print \"S.shape\", S.shape\n",
    "\n",
    "print \"innovations[2]\", innovations[2]\n",
    "print \"innovations[2].shape\", np.array(innovations[2]).shape\n",
    "d = np.array([[innovations[2,0]], [innovations[2,1]]])\n",
    "print \"d\", d\n",
    "print \"d.shape\", d.shape\n",
    "\n",
    "# K = Q H^T S d\n",
    "#   = U_GB Q_soar Q_soar U_GB^T H^T S d\n",
    "e = np.dot(S, d)\n",
    "print \"e\", e\n",
    "HTe = np.dot(H.transpose(), e)\n",
    "print \"HTe.shape\", HTe.shape\n",
    "\n",
    "UTHTe = np.dot(U_GB.transpose(), HTe)\n",
    "QUTHTe = np.dot(Q_soar.transpose(), UTHTe)\n",
    "halfway = np.reshape(QUTHTe, (ny, nx))\n",
    "#showMatrices(halfway, halfway, \"halfway matrix\", halfway)\n",
    "QQUTHTe = np.dot(Q_soar, QUTHTe)\n",
    "K = np.dot(U_GB, QQUTHTe)\n",
    "\n",
    "print \"K.shape\", K.shape\n",
    "K_eta_matrix = np.reshape(K[       :nx*ny  ], (ny, nx))\n",
    "K_hu_matrix  = np.reshape(K[  nx*ny:2*nx*ny], (ny, nx))\n",
    "K_hv_matrix  = np.reshape(K[2*nx*ny:       ], (ny, nx))\n",
    "showMatrices(K_eta_matrix, K_hu_matrix, \"Kalman gains from matrices\", K_hv_matrix)\n",
    "\n",
    "K_eta_abs_diff = np.abs(K_eta_matrix - K_eta)\n",
    "K_hu_abs_diff  = np.abs( K_hu_matrix - K_hu )\n",
    "K_hv_abs_diff  = np.abs( K_hv_matrix - K_hv )\n",
    "showMatrices(K_eta_abs_diff, K_hu_abs_diff, \"K abs differences\", K_hv_abs_diff)\n",
    "\n",
    "\n",
    "\n",
    "#######################\n",
    "\n",
    "eta, hu, hv = ensemble.particles[2].download(interior_domain_only=True)\n",
    "true_eta, true_hu, true_hv = ensemble.particles[ensemble.obs_index].download(interior_domain_only=True)\n",
    "\n",
    "print \"-----------------------------------\"\n",
    "print \"Observation:          \", ensemble.observeTrueState()\n",
    "print \"Observed particle pos:\", observed_drifter_position\n",
    "print \"True velocity:        \", [true_hu[cell_id_y, cell_id_x], true_hv[cell_id_y, cell_id_x]]\n",
    "print \"Particle velocity:    \", [hu[cell_id_y, cell_id_x], hv[cell_id_y, cell_id_x]]\n",
    "print \"Ocean depth:          \", np.max(ensemble.base_H)\n",
    "\n",
    "print \"---------\"\n",
    "print \"innovation:           \", innovations[2]\n",
    "#print \"y - particle velocity:\", [\n",
    "print \"stencil [K_hu, K_hv]: \", [K_hu[cell_id_y, cell_id_x], K_hv[cell_id_y, cell_id_x]]\n",
    "print \"matrix  [K_hu, K_hv]: \", [K_hu_matrix[cell_id_y, cell_id_x], K_hv_matrix[cell_id_y, cell_id_x]]\n",
    "print \"                 H*K: \", np.dot(H, K)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# Investigating the innermost term of $P$\n",
    "\n",
    "Step 2 of the IEWPF algorithm consists of drawing $\\xi \\sim N(0, P)$, meaning that we have to find $\\xi = P^{1/2} \\tilde{\\xi}$, in which $\\tilde{\\xi} \\sim N(0, I)$ and $P$ is given by\n",
    "$$ P = Q - Q H^T (HQH^T + R)^{-1} H Q \\\\\n",
    "\t  \\qquad = Q^{1/2}(I - Q^{1/2, T}H^T S H Q^{1/2})Q^{1/2,T} \\\\\n",
    "      \\qquad = Q^{1/2}(I - \\tilde{P})Q^{1/2,T} $$\n",
    "In order to find $P^{1/2}$, we need to express $(I - \\tilde{P})^{1/2}$. This will be done through a singular value decomposition of $(I - \\tilde{P})$.\n",
    "\n",
    "By considering the local structure of $Q^{1/2}$ and the size of the size of the observation operator $H$, we see that $\\tilde{P}$ will be matrix which is zero everywhere, except in a $7 \\times 7$ neighbour block, where the location of the block depends on the position of the observed drifter. Since $H$ will change, $P$ is subject to change as well, but the structure of $P$ will be constant. We can therefore obtain $P^{1/2}$ based on the SVD of the non-zero block of $(I-\\tilde{P})$. \n",
    "\n",
    "\n",
    "The aim of the code below is to obtain the full matrix $\\tilde{P}$, and confirm that we can calculate the SVD of $(I - \\tilde{P})$.\n",
    "By using \n",
    "$$(I - \\tilde{P}) = U \\Sigma V^T,$$ \n",
    "where $\\Sigma$ is a diagonal matrix, we now get \n",
    "$$P = Q^{1/2} U \\Sigma^{1/2} \\Sigma^{1/2} V^T Q^{1/2, T} \\\\\n",
    "\t  \\quad \\qquad = U_{GB} \\tilde{Q}^{1/2} U \\Sigma^{1/2} \\Sigma^{1/2} V^T \\tilde{Q}^{1/2} U_{GB}^T$$\n",
    "\n",
    "Using the convention $P = P^{1/2} P^{1/2, T}$, we get a $\\xi \\sim N(0, P)$ as\n",
    "$$ \\xi  = U_{GB} \\tilde{Q}^{1/2} U \\Sigma^{1/2} \\tilde{\\xi}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def periodic_SOAR_Q(a_x, a_y, b_x, b_y, dx, dy, nx, ny, q0, L):\n",
    "    dist_x = min((a_x - b_x)**2, (a_x - (b_x + nx))**2, (a_x - (b_x - nx))**2)\n",
    "    dist_y = min((a_y - b_y)**2, (a_y - (b_y + ny))**2, (a_y - (b_y - ny))**2)\n",
    "    \n",
    "    dist = np.sqrt( dx*dx*dist_x  +  dy*dy*dist_y)\n",
    "    \n",
    "    return q0*(1.0 + dist/L)*np.exp(-dist/L)\n",
    "\n",
    "def createCutoffMatrixQ(nx, ny, dx=1.0, dy=1.0, q0=1.0, L=1.0, cutoff=2):\n",
    "    Q = np.zeros((ny*nx, ny*nx))\n",
    "    for a_y in range(ny):\n",
    "        for a_x in range(nx):\n",
    "            j = a_y*nx + a_x\n",
    "            for b_y in range(a_y-cutoff, a_y+cutoff+1):\n",
    "                if b_y < 0:    \n",
    "                     b_y = b_y + ny\n",
    "                if b_y > ny-1: \n",
    "                    b_y = b_y - ny\n",
    "                for b_x in range(a_x-cutoff, a_x+cutoff+1):\n",
    "                    if b_x < 0:\n",
    "                        b_x = b_x + nx\n",
    "                    if b_x > nx-1: \n",
    "                        b_x = b_x - nx\n",
    "                    i = b_y*nx + b_x\n",
    "                    Q[j, i] = periodic_SOAR_Q(a_x, a_y, b_x, b_y, dx, dy, nx, ny, q0, L)\n",
    "    return Q\n",
    "\n",
    "def createFullMatrixQ(nx, ny, dx=1, dy=1, q0=1, L=1):\n",
    "    Q = np.zeros((ny*nx, ny*nx))\n",
    "    for a_y in range(ny):\n",
    "        for a_x in range(nx):\n",
    "            j = a_y*nx + a_x\n",
    "            for b_y in range(ny):\n",
    "                for b_x in range(nx):\n",
    "                    i = b_y*nx + b_x\n",
    "                    Q[j, i] = periodic_SOAR_Q(a_x, a_y, b_x, b_y, dx, dy, nx, ny, q0, L)\n",
    "    return Q\n",
    "\n",
    "nx = 10\n",
    "ny = 10\n",
    "dx = ensemble.dx\n",
    "dy = ensemble.dy\n",
    "L = 0.75*dx\n",
    "g = ensemble.g\n",
    "q0 = ensemble.small_scale_perturbation_amplitude\n",
    "Q = createCutoffMatrixQ(nx, ny, dx, dy, q0=q0, L=L)\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(Q, interpolation=\"None\")\n",
    "plt.title(\"SOAR Q (cutoff)\")\n",
    "plt.colorbar()\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(Q == 0.0, interpolation=\"None\")\n",
    "\n",
    "#fullQ = createFullMatrixQ(nx, ny, L=L, q0=q0)\n",
    "#fig = plt.figure(figsize=(4,4))\n",
    "#plt.imshow(fullQ, interpolation=\"None\")\n",
    "#plt.title(\"SOAR Q (full)\")\n",
    "#plt.colorbar()\n",
    "#fig = plt.figure(figsize=(4,4))\n",
    "#plt.imshow(Q - fullQ, interpolation=\"None\")\n",
    "#plt.colorbar()\n",
    "#plt.title(\"SOAR Q (cutoff - diff)\")\n",
    "\n",
    "\n",
    "\n",
    "def createUGBmatrix(nx, ny, g=9.81, H=10, f=30, dx=1.0, dy=1.0):\n",
    "    I = np.eye(nx*ny)\n",
    "    A_hu = np.zeros((ny*nx, ny*nx))\n",
    "    A_hv = np.zeros((ny*nx, ny*nx))\n",
    "    for a_y in range(ny):\n",
    "        for a_x in range(nx):\n",
    "            i = a_y*nx + a_x\n",
    "            \n",
    "            # geo balance for hu:\n",
    "            j = (a_y+1)*nx + a_x\n",
    "            if a_y == ny-1:\n",
    "                j = 0*nx + a_x\n",
    "            A_hu[j,i] = 1.0\n",
    "            j = (a_y-1)*nx + a_x\n",
    "            if a_y == 0:\n",
    "                j = (ny-1)*nx + a_x\n",
    "            A_hu[j,i] = -1.0\n",
    "            \n",
    "            # geo balance for hv:\n",
    "            j = a_y*nx + a_x + 1\n",
    "            if a_x == nx-1:\n",
    "                j = a_y*nx + 0\n",
    "            A_hv[j,i] = 1.0\n",
    "            \n",
    "            j = a_y*nx + a_x - 1\n",
    "            if a_x == 0:\n",
    "                j = a_y*nx + nx - 1\n",
    "            A_hv[j,i] = -1.0\n",
    "            \n",
    "    A_hu *= -g*H/(f*2*dx)\n",
    "    A_hv *=  g*H/(f*2*dy)\n",
    "            \n",
    "    return np.bmat([[I], [A_hu], [A_hv]])\n",
    "\n",
    "\n",
    "    \n",
    "U = createUGBmatrix(nx, ny, g=g, H=waterDepth, f=ensemble.f, dx=dx, dy=dy)\n",
    "fig = plt.figure(figsize=(4,8))\n",
    "plt.imshow(U, interpolation=\"None\")\n",
    "plt.title(\"U\")\n",
    "plt.colorbar()\n",
    "\n",
    "\n",
    "S = np.matrix([[2.0, 0.0], [0.0, 2.0]])\n",
    "fig = plt.figure(figsize=(2,2))\n",
    "plt.imshow(S, interpolation=\"None\")\n",
    "plt.title(\"S\")\n",
    "plt.colorbar()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "pos_x, pos_y = 5, 5\n",
    "\n",
    "def createMatrixH(nx, ny, pos_x, pos_y):\n",
    "    H = np.zeros((2, 3*nx*ny))\n",
    "    index = pos_y*nx + pos_x\n",
    "    H[0, 1*nx*ny + index] = 1\n",
    "    H[1, 2*nx*ny + index] = 1\n",
    "    return H\n",
    "\n",
    "H = createMatrixH(nx, ny, pos_x, pos_y)\n",
    "print \"H.shape\", H.shape\n",
    "fig = plt.figure(figsize=(20,2))\n",
    "plt.imshow(H, interpolation=\"None\", cmap=\"cool\")\n",
    "plt.title(\"H\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using $Q = U_{GB} \\tilde{Q}^{1/2} \\tilde{Q}^{1/2} U_{GB}^T$, where $\\tilde{Q}^{1/2}$ is symmetric, we get \n",
    "$$\\tilde{P} = \\tilde{Q}^{1/2} U_{GB}^T H^T S H U_{GB} \\tilde{Q}^{1/2}$$\n",
    "\n",
    "We go through the computations of\u00c2\u00a0$\\tilde{P}$ step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "UQ = np.matmul(U, Q)\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(UQ, interpolation=\"None\")\n",
    "plt.title(\"UQ\")\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HUQ = np.matmul(H, UQ)\n",
    "fig = plt.figure(figsize=(20,2))\n",
    "plt.imshow(HUQ, interpolation=\"None\")\n",
    "plt.title(\"HUQ\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SHUQ = np.matmul(S, HUQ)\n",
    "fig = plt.figure(figsize=(20,2))\n",
    "plt.imshow(SHUQ, interpolation=\"None\")\n",
    "plt.title(\"SHUQ\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTSHUQ = np.matmul(H.transpose(), SHUQ)\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(HTSHUQ, interpolation=\"None\")\n",
    "plt.title(\"HTSHUQ\")\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "UTHTSHUQ = np.matmul(U.transpose(), HTSHUQ)\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(UTHTSHUQ, interpolation=\"None\")\n",
    "plt.title(\"UTHTSHUQ\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tildeP = np.matmul(Q, UTHTSHUQ)\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(tildeP, interpolation=\"None\")\n",
    "plt.title(\"tilde(P) = QUTHTSHUQ\")\n",
    "plt.colorbar()\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(tildeP == 0, interpolation=\"None\")\n",
    "plt.title(\"tilde(P) non-zeros\")\n",
    "plt.colorbar()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extractNonZeroBlocks(tildeP, nx, ny, pos_x, pos_y):\n",
    "    \n",
    "    # The Q^{1/2} U_GB^T pattern spreads information to a 7x7 cell area, but without the corners\n",
    "    # Hence, the nonzero structure of tilde{P} should be a block of 7x7-4 = 49-4 = 45 rows and cells.\n",
    "    \n",
    "    # Strategy: Fill 49 by 49 area\n",
    "    \n",
    "    tildeP_block = np.zeros((49,49))\n",
    "    \n",
    "    # Read the non-zero structure from tildeP to tildeP_block\n",
    "    for loc_y_j in range(7):\n",
    "        global_y_j = pos_y - 3 + loc_y_j\n",
    "        for loc_x_j in range(7):\n",
    "            global_x_j = pos_x - 3 + loc_x_j\n",
    "            \n",
    "            global_j = global_y_j*nx + global_x_j\n",
    "            local_j = loc_y_j*7 + loc_x_j\n",
    "            \n",
    "            for loc_y_i in range(7):\n",
    "                global_y_i = pos_y - 3 + loc_y_i\n",
    "                for loc_x_i in range(7):\n",
    "                    global_x_i = pos_x - 3 + loc_x_i\n",
    "                    \n",
    "                    global_i = global_y_i*nx + global_x_i\n",
    "                    local_i = loc_y_i*7 + loc_x_i\n",
    "                    \n",
    "                    tildeP_block[local_j, local_i] = tildeP[global_j, global_i] \n",
    "    \n",
    "    # Delete the rows and arrays that should not take part of the block\n",
    "    #local_indices_to_delete = [0, 6, 49-7, 49-1]\n",
    "    #tildeP_block = np.delete(tildeP_block, local_indices_to_delete, 0)\n",
    "    #tildeP_block = np.delete(tildeP_block, local_indices_to_delete, 1)\n",
    "    \n",
    "    validate = False\n",
    "    if validate:\n",
    "        nz_y, nz_x = np.nonzero(tildeP)\n",
    "        print len(nz_y), nz_y\n",
    "        print len(nz_x), nz_x\n",
    "        print 7*7*7*7 \n",
    "\n",
    "\n",
    "        unique_nz_y = np.unique(nz_y)\n",
    "        unique_nz_x = np.unique(nz_x)\n",
    "\n",
    "        print len(unique_nz_y), unique_nz_y\n",
    "        print len(unique_nz_x), unique_nz_x\n",
    "        validation = tildeP[unique_nz_y, :]\n",
    "        validation = validation[:, unique_nz_x]\n",
    "        validation_nz_y, validation_nz_x = np.nonzero(validation)\n",
    "        print \"Num nonzeros validation:  \", len(validation_nz_y), len(validation_nz_x)\n",
    "\n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "        plt.imshow(validation, interpolation=\"None\")\n",
    "        plt.title(\"validation for tilde(P) non-zeros block\")\n",
    "        plt.colorbar()\n",
    "\n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "        plt.imshow(tildeP_block, interpolation=\"None\")\n",
    "        plt.title(\"tildeP_block\")\n",
    "        plt.colorbar()\n",
    "\n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "        plt.imshow(tildeP_block - validation, interpolation=\"None\")\n",
    "        plt.title(\"tildeP_block - validation\")\n",
    "        plt.colorbar()\n",
    "    \n",
    "    return tildeP_block\n",
    "    \n",
    "    \n",
    "tildeP_block = extractNonZeroBlocks(tildeP, nx, ny, pos_x, pos_y )\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(tildeP_block, interpolation=\"None\")\n",
    "plt.title(\"tilde(P) non-zeros block\")\n",
    "plt.colorbar()\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(tildeP_block == 0, interpolation=\"None\")\n",
    "plt.title(\"tilde(P) non-zeros block nonzeros\")\n",
    "plt.colorbar()\n",
    "\n",
    "print \"tildeP_block.shape\", tildeP_block.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the Singular-Value Decomposition\n",
    "\n",
    "Need the SVD so that \n",
    "$$ (I - \\tilde{P}) = U \\Sigma V^T = U \\Sigma^{1/2} \\Sigma^{1/2} V^T $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "svd_block_input = np.eye(49) - tildeP_block\n",
    "u, s, vh = np.linalg.svd(svd_block_input, full_matrices=True)\n",
    "\n",
    "print \"u: \", u.shape\n",
    "print \"s: \", s.shape\n",
    "print \"vh:\", vh.shape\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "plt.subplot(131)\n",
    "plt.imshow(u, interpolation=\"None\")\n",
    "plt.title(\"u\")\n",
    "plt.colorbar()\n",
    "plt.subplot(132)\n",
    "plt.imshow(np.diag(s), interpolation=\"None\")\n",
    "plt.title(\"s\")\n",
    "plt.colorbar()\n",
    "plt.subplot(133)\n",
    "plt.imshow(vh, interpolation=\"None\")\n",
    "plt.title(\"vh\")\n",
    "plt.colorbar()\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(u - vh.transpose(), interpolation=\"None\")\n",
    "plt.title(\"u - vh\")\n",
    "plt.colorbar()\n",
    "\n",
    "svd_block_output = np.matmul(u, np.matmul(np.diag(s), vh))\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(svd_block_output, interpolation=\"None\")\n",
    "plt.title(\"svd_block_output\")\n",
    "plt.colorbar()\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(svd_block_input - svd_block_output, interpolation=\"None\")\n",
    "plt.title(\"svd_block_input - svd_block_output\")\n",
    "plt.colorbar()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(np.abs(svd_block_output) < 0.00000001, interpolation=\"None\")\n",
    "plt.title(\"svd_block_output non-zeros\")\n",
    "plt.colorbar()\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(np.abs(svd_block_input) < 0.00000001, interpolation=\"None\")\n",
    "plt.title(\"svd_block_input non-zeros\")\n",
    "plt.colorbar()\n",
    "\n",
    "\n",
    "print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqrt_term = np.matmul(u, np.diag(np.sqrt(s)))\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(sqrt_term, interpolation=\"None\")\n",
    "plt.title(\"sqrt_term\")\n",
    "plt.colorbar()\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(np.dot(sqrt_term, sqrt_term.transpose()) - np.eye(49), interpolation=\"None\")\n",
    "plt.title(\"sqrt_term * sqrt_term^T\")\n",
    "plt.colorbar()\n",
    "\n",
    "onesies = np.ones(49)\n",
    "onesies = np.dot(sqrt_term, onesies)\n",
    "onesies = onesies.reshape((7,7))\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(onesies, interpolation=\"None\")\n",
    "plt.title(\"sqrt_term * onesies\")\n",
    "\n",
    "print \"sqrt_term.shape\", sqrt_term.shape\n",
    "\n",
    "filename = \"svd_tests/local_sqrt_term_nx_\" + str(nx) + \"_ny_\" + str(ny) + \"_posx_\" + str(pos_x) + \"_posy_\" + str(pos_y) +\".npy\"\n",
    "print filename\n",
    "np.save(filename, sqrt_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping the SVD-block back to the global domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extendSVDBlock(svd_block, nx, ny, pos_x, pos_y):\n",
    "    \n",
    "    # The Q^{1/2} U_GB^T pattern spreads information to a 7x7 cell area, but without the corners\n",
    "    # Hence, the nonzero structure of tilde{P} should be a block of 7x7-4 = 49-4 = 45 rows and cells.\n",
    "    \n",
    "    # Strategy: Fill 49 by 49 area\n",
    "    \n",
    "    global_svd = np.eye(nx*ny)\n",
    "    \n",
    "    # Read the non-zero structure from tildeP to tildeP_block\n",
    "    for loc_y_j in range(7):\n",
    "        global_y_j = pos_y - 3 + loc_y_j\n",
    "        for loc_x_j in range(7):\n",
    "            global_x_j = pos_x - 3 + loc_x_j\n",
    "            \n",
    "            global_j = global_y_j*nx + global_x_j\n",
    "            local_j = loc_y_j*7 + loc_x_j\n",
    "            \n",
    "            for loc_y_i in range(7):\n",
    "                global_y_i = pos_y - 3 + loc_y_i\n",
    "                for loc_x_i in range(7):\n",
    "                    global_x_i = pos_x - 3 + loc_x_i\n",
    "                    \n",
    "                    global_i = global_y_i*nx + global_x_i\n",
    "                    local_i = loc_y_i*7 + loc_x_i\n",
    "                    \n",
    "                    global_svd[global_j, global_i] = svd_block[local_j, local_i]\n",
    "    return global_svd            \n",
    "        \n",
    "global_svd = extendSVDBlock(svd_block_output, nx, ny, pos_x, pos_y)\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(global_svd, interpolation=\"None\")\n",
    "plt.title(\"global_svd \")\n",
    "plt.colorbar()\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(np.abs(global_svd) < 0.00000001, interpolation=\"None\")\n",
    "plt.title(\"global_svd non-zeros\")\n",
    "plt.colorbar()\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(np.abs(svd_block_output) < 0.00000001, interpolation=\"None\")\n",
    "plt.title(\"svd_block_output non-zeros\")\n",
    "plt.colorbar()\n",
    "\n",
    "eyeMinusTildeP = np.eye(nx*ny) - tildeP\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(global_svd - eyeMinusTildeP, interpolation=\"None\")\n",
    "plt.title(\"global_svd - eyeMinusTildeP\")\n",
    "plt.colorbar()\n",
    "\n",
    "global_sqrt_term = extendSVDBlock(sqrt_term, nx, ny, pos_x, pos_y)\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(global_sqrt_term, interpolation=\"None\")\n",
    "plt.title(\"global_sqrt_term \")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply local and global $U \\Sigma^{1/2}$ to vector\n",
    "And see that the results are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glob_v = np.random.rand(nx*ny)\n",
    "\n",
    "def global_to_local_vec(glob_vec, nx, ny, pos_x, pos_y):\n",
    "    \n",
    "    # Strategy: go from vec nx*ny to vec 49\n",
    "    \n",
    "    loc_vec = np.zeros(49)\n",
    "    \n",
    "    # Read the non-zero structure from tildeP to tildeP_block\n",
    "    for loc_y_j in range(7):\n",
    "        global_y_j = pos_y - 3 + loc_y_j\n",
    "        for loc_x_j in range(7):\n",
    "            global_x_j = pos_x - 3 + loc_x_j\n",
    "            \n",
    "            global_j = global_y_j*nx + global_x_j\n",
    "            local_j = loc_y_j*7 + loc_x_j\n",
    "            \n",
    "            loc_vec[local_j] = glob_vec[global_j]\n",
    "    return loc_vec\n",
    "\n",
    "def write_local_to_global_vec(glob_vec, loc_vec, nx, ny, pos_x, pos_y):\n",
    "    \n",
    "    # Write the elements in loc_vec to the appropriate locations in glob_vec\n",
    "        \n",
    "    # Read the non-zero structure from tildeP to tildeP_block\n",
    "    for loc_y_j in range(7):\n",
    "        global_y_j = pos_y - 3 + loc_y_j\n",
    "        for loc_x_j in range(7):\n",
    "            global_x_j = pos_x - 3 + loc_x_j\n",
    "            \n",
    "            global_j = global_y_j*nx + global_x_j\n",
    "            local_j = loc_y_j*7 + loc_x_j\n",
    "            \n",
    "            glob_vec[global_j] = loc_vec[local_j]\n",
    "    \n",
    "# This is the function that needs to be implemented on GPU\n",
    "def apply_local_SVD_to_global_eta(local_sqrt_term, global_eta, nx, ny, pos_x, pos_y):\n",
    "    \"\"\"\n",
    "    Despite the bad name, this is a good function!\n",
    "    \n",
    "    It takes as input:\n",
    "     - local sqrt(SVD) as U*sqrt(Sigma) in a (49, 49) buffer \n",
    "     - the global xi stored in a (ny, nx) buffer\n",
    "     \n",
    "    It returns the product of the first and second argument, as U*sqrt(Sigma)*xi, in a (ny, nx) buffer \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Copy the result (representing the multiplication with I)\n",
    "    res_global_eta = global_eta.copy()\n",
    "    \n",
    "    # Read the non-zero structure from tildeP to tildeP_block\n",
    "    for loc_y_j in range(7):\n",
    "        global_y_j = pos_y - 3 + loc_y_j\n",
    "        for loc_x_j in range(7):\n",
    "            global_x_j = pos_x - 3 + loc_x_j\n",
    "            \n",
    "            global_j = global_y_j*nx + global_x_j\n",
    "            local_j = loc_y_j*7 + loc_x_j\n",
    "            \n",
    "            #loc_vec[local_j] = glob_vec[global_j]\n",
    "            \n",
    "            xi_j = 0.0\n",
    "            for loc_y_i in range(7):\n",
    "                global_y_i = pos_y - 3 + loc_y_i\n",
    "                for loc_x_i in range(7):\n",
    "                    global_x_i = pos_x - 3 + loc_x_i\n",
    "                    \n",
    "                    global_i = global_y_i*nx + global_x_i\n",
    "                    local_i = loc_y_i*7 + loc_x_i\n",
    "                    \n",
    "                    xi_j += local_sqrt_term[local_j, local_i]*global_eta[global_y_i, global_x_i]\n",
    "            \n",
    "            res_global_eta[global_y_j, global_x_j] = xi_j\n",
    "            \n",
    "    return res_global_eta\n",
    "            \n",
    "# Check that the above functions works:\n",
    "loc_v = global_to_local_vec(glob_v, nx, ny, pos_x, pos_y)\n",
    "copy_glob_v = glob_v.copy()\n",
    "write_local_to_global_vec(glob_v, loc_v, nx, ny, pos_x, pos_y)\n",
    "print \"Dummy diff (should be zero): \", np.linalg.norm(glob_v - copy_glob_v)\n",
    "\n",
    "loc_res = np.dot(sqrt_term, loc_v)\n",
    "write_local_to_global_vec(glob_v, loc_res, nx, ny, pos_x, pos_y)\n",
    "fasit = np.dot(global_sqrt_term, copy_glob_v)\n",
    "\n",
    "print \"Result diff (should be zero): \", np.linalg.norm(glob_v - fasit)\n",
    "print \"Diff from multiplying the sqrt_term: \", np.linalg.norm(glob_v - copy_glob_v)\n",
    "applying_sqrt_term_diff = glob_v - copy_glob_v\n",
    "\n",
    "applying_sqrt_term_diff = applying_sqrt_term_diff.reshape((ny,nx))\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(applying_sqrt_term_diff, interpolation=\"None\")\n",
    "plt.title(\"applying_sqrt_term_diff \")\n",
    "plt.colorbar()\n",
    "\n",
    "glob_v = glob_v.reshape((ny,nx))\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(glob_v, interpolation=\"None\")\n",
    "plt.title(\"glob_v\")\n",
    "plt.colorbar()\n",
    "\n",
    "copy_glob_v_eta_shape = copy_glob_v.reshape((ny,nx))\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(copy_glob_v_eta_shape, interpolation=\"None\")\n",
    "plt.title(\"copy_glob_v_eta_shape\")\n",
    "plt.colorbar()\n",
    "\n",
    "print copy_glob_v_eta_shape[0,4], copy_glob_v[4]\n",
    "\n",
    "# Testing the function that will be implemented on GPU\n",
    "local_SVD_on_global_vector = apply_local_SVD_to_global_eta(sqrt_term, copy_glob_v_eta_shape, nx, ny, pos_x, pos_y) \n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(local_SVD_on_global_vector - glob_v, interpolation=\"None\")\n",
    "plt.title(\"local_SVD_on_global_vector - glob_v \")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Reading different files to see if the SVD terms are the same\n",
    "\n",
    "The below code confirms that the local block for $U \\Sigma^{1/2}$ is the same for different domain sizes and for different observation positions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sqrt_term_10_10_5_5 = np.load(\"svd_tests/local_sqrt_term_nx_10_ny_10_posx_5_posy_5.npy\")\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(sqrt_term_10_10_5_5, interpolation=\"None\")\n",
    "plt.title(\"sqrt_term_10_10_5_5 \")\n",
    "plt.colorbar()\n",
    "\n",
    "sqrt_term_10_10_3_3 = np.load(\"svd_tests/local_sqrt_term_nx_10_ny_10_posx_3_posy_3.npy\")\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(sqrt_term_10_10_5_5, interpolation=\"None\")\n",
    "plt.title(\"sqrt_term_10_10_5_5 \")\n",
    "plt.colorbar()\n",
    "\n",
    "sqrt_term_15_15_10_10 = np.load(\"svd_tests/local_sqrt_term_nx_15_ny_15_posx_10_posy_10.npy\")\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(sqrt_term_15_15_10_10, interpolation=\"None\")\n",
    "plt.title(\"sqrt_term_15_15_10_10 \")\n",
    "plt.colorbar()\n",
    "\n",
    "\n",
    "sqrt_term_7_7_3_3 = np.load(\"svd_tests/local_sqrt_term_nx_7_ny_7_posx_3_posy_3.npy\")\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(sqrt_term_7_7_3_3, interpolation=\"None\")\n",
    "plt.title(\"sqrt_term_7_7_3_3 \")\n",
    "plt.colorbar()\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(sqrt_term_10_10_5_5 - sqrt_term_10_10_3_3 , interpolation=\"None\")\n",
    "plt.title(\"sqrt_term_10_10_5_5 - sqrt_term_10_10_3_3 \")\n",
    "plt.colorbar()\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(sqrt_term_10_10_5_5 - sqrt_term_15_15_10_10 , interpolation=\"None\")\n",
    "plt.title(\"sqrt_term_10_10_5_5 - sqrt_term_15_15_10_10 \")\n",
    "plt.colorbar()\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(sqrt_term_7_7_3_3 - sqrt_term_15_15_10_10 , interpolation=\"None\")\n",
    "plt.title(\"sqrt_term_7_7_3_3 - sqrt_term_15_15_10_10 \")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating matrix $S = (HQH^T + R)^{-1}$\n",
    "$$S = (H U_{GB} \\tilde{Q}^{1/2} \\tilde{Q}^{1/2} U_{GB}^T + R)^{-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print (nx, ny, ensemble.dx, ensemble.dy, pos_x, pos_y, q0, L)\n",
    "\n",
    "H = createMatrixH(nx, ny, pos_x, pos_y)\n",
    "Qtilde = createCutoffMatrixQ(nx, ny, dx=ensemble.dx, dy=ensemble.dy, L=0.75*dx, q0=q0)\n",
    "U_GB = createUGBmatrix(nx, ny, g=ensemble.g, H=np.max(ensemble.base_H), f=ensemble.f, dx=ensemble.dx, dy=ensemble.dy)\n",
    "\n",
    "print \"g*H/(f*2*dx)\", ensemble.g*np.max(ensemble.base_H)/(ensemble.f*2*ensemble.dx)\n",
    "\n",
    "fig = plt.figure(figsize=(20,2))\n",
    "plt.imshow(H, interpolation=\"None\", cmap=\"cool\")\n",
    "plt.title(\"H\")\n",
    "plt.colorbar()\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(Qtilde, interpolation=\"None\")\n",
    "plt.title(\"Qtilde\")\n",
    "plt.colorbar()\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(U_GB, interpolation=\"None\")\n",
    "plt.title(\"U_GB\")\n",
    "plt.colorbar()\n",
    "print \"U_GB.shape: \", U_GB.shape\n",
    "\n",
    "Q_sqrt = np.dot(U_GB, Qtilde)\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(Q_sqrt, interpolation=\"None\")\n",
    "plt.title(\"Q_sqrt\")\n",
    "plt.colorbar()\n",
    "\n",
    "Q = np.dot(Q_sqrt, Q_sqrt.transpose())\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(Q, interpolation=\"None\")\n",
    "plt.title(\"Q\")\n",
    "plt.colorbar()\n",
    "\n",
    "HQHT = np.dot(H, np.dot(Q, H.transpose()))\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(HQHT, interpolation=\"None\")\n",
    "plt.title(\"HQHT\")\n",
    "plt.colorbar()\n",
    "print \"HQHT\"\n",
    "print HQHT\n",
    "\n",
    "print \"S from matrix multiplications: \"\n",
    "print np.linalg.inv(HQHT + ensemble.observation_cov)\n",
    "\n",
    "debug=False\n",
    "S = createS(ensemble, 10.0)\n",
    "print \"S from createS function: \"\n",
    "print S\n",
    "\n",
    "print \"np.max(ensemble.base_H)\", np.max(ensemble.base_H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}