{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "This notebook sets up and runs a set of benchmarks to compare\n",
    "different numerical discretizations of the SWEs\n",
    "\n",
    "Copyright (C) 2016  SINTEF ICT\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Particle Filter\n",
    "\n",
    "In this notebook we will make test implementations of basic particle filters.\n",
    "\n",
    "The aim is to find a decent implementation of the particles, which can be used by both simulators and particle filter.\n",
    "\n",
    "All post-processing of particles will be done on the CPU in this first iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of basic resampling strategies\n",
    "\n",
    "The following four resampling algorithms are described in Section 3a) in van Leeuven's 2009 review paper.\n",
    "\n",
    "The starting point is a prior distribution of model states with pdf $p(\\psi^0)$, from which $N$ model state samples (particles) $\\psi_i^0$, $i = 1,...,N$ are drawn.\n",
    "Run the simulation model on all particles $\\psi_i^n = f(\\psi_i^{n-1})$. This is the same as sampling from the $p(\\psi^n | \\psi_i^{n-1})$.\n",
    "At this point we see an observation $d$.\n",
    "\n",
    "Now, define a posterior distribution $p(\\psi^n | d)$. **Think a bit here before writing more** - from this we obtain weights $w_i$.\n",
    "\n",
    "\n",
    "The most basic resampling strategies are as follows:\n",
    "### Probabilistic resampling\n",
    "Use the weights as a discrete distribution and sample directly from this.\n",
    "\n",
    "### Residual sampling\n",
    "Here, we first resample particles deterministic based on their weights. Resample particle $i$ np.floor$(Nw_i)$ times. Define the left-over weights as $w^*_i = Nw_i \\% 1$, and use $w^*_i$ as a discrete distribution, from which the reminder resampled particles are drawn from, until we have $N$ particles again.\n",
    "\n",
    "**Note:** It is here recommended to use Cauchy distribution as the observation pdf.\n",
    "\n",
    "### Stochastic Universal sampling\n",
    "Put all weights as buckets on the line $[0, 1]$, and draw a random number $u \\sim U[0, 1/N]$.\n",
    "Put $N$ line pieces starting from $u$ with length $1/N$ are laid on the line $[0,1]$. \n",
    "The bucket in which each line piece ends (not started???) defines which particle is chosen for each of the $N$ line pieces.\n",
    "\n",
    "### Monte Carlo Metropolis-Hastings sampling\n",
    "This sampling scheme is described very algorithmic in the paper already, so take a look at 3a4).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import modules and set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lets have matplotlib \"inline\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "#Import packages we need\n",
    "import numpy as np\n",
    "from matplotlib import animation, rc\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "\n",
    "import os\n",
    "import pyopencl\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "#Set large figure sizes\n",
    "rc('figure', figsize=(16.0, 12.0))\n",
    "rc('animation', html='html5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make sure we get compiler output from OpenCL\n",
    "os.environ[\"PYOPENCL_COMPILER_OUTPUT\"] = \"1\"\n",
    "\n",
    "#Set which CL device to use, and disable kernel caching\n",
    "if (str.lower(sys.platform).startswith(\"linux\")):\n",
    "    os.environ[\"PYOPENCL_CTX\"] = \"0\"\n",
    "else:\n",
    "    os.environ[\"PYOPENCL_CTX\"] = \"1\"\n",
    "os.environ[\"CUDA_CACHE_DISABLE\"] = \"1\"\n",
    "os.environ[\"PYOPENCL_COMPILER_OUTPUT\"] = \"1\"\n",
    "os.environ[\"PYOPENCL_NO_CACHE\"] = \"1\"\n",
    "\n",
    "#Create OpenCL context\n",
    "cl_ctx = pyopencl.create_some_context()\n",
    "print \"Using \", cl_ctx.devices[0].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thoughts on code structure\n",
    "\n",
    "The observation will in these initial cases be a chosen model realization. When initializing a data assimilation with N particles, N+1 particles should be created and distributed on simulators.\n",
    "\n",
    "One hypothesis for our ocean simulator is that integrating 100 particles within the same simulation is equally expensive as integrating 1 particle. Each particle integration should be done with a single thread on the GPU, so all 100 particles will can be processed in parallel.\n",
    "\n",
    "If this assumption is true, it is best to have all particle positions continuous in memory. Hence, it will be implemented as an struct of array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create random particles, and create random observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Seed so that all simulation runs are equal.\n",
    "np.random.seed(10)\n",
    "\n",
    "print np.zeros((2,3))\n",
    "print np.ones(4)\n",
    "a = np.random.rand(3,2)\n",
    "print a\n",
    "print a.shape\n",
    "print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### GlobalParticlesClass\n",
    "\n",
    "class GlobalParticles:\n",
    "    def __init__(self, numParticles):\n",
    "        \n",
    "        self.numParticles = numParticles\n",
    "        \n",
    "        # Observation index is the last particle\n",
    "        self.obs_index = self.numParticles \n",
    "        self.observation_gamma = 0.1\n",
    "        \n",
    "        # One position for every particle plus observation\n",
    "        self.positions = np.zeros((self.numParticles + 1, 2))\n",
    "        \n",
    "    def initializeUnitSquare(self):\n",
    "        self.positions = np.random.rand(self.numParticles + 1, 2)\n",
    "    \n",
    "        # Ensure that the observation is in the middle 0.5x0.5 square:\n",
    "        self.positions[self.obs_index, :] = self.positions[self.obs_index]*0.5 + 0.25\n",
    "        \n",
    "    def getDistances(self):\n",
    "        distances = np.zeros(self.numParticles)\n",
    "        for i in range(self.numParticles):\n",
    "            distances[i] = np.sqrt( (self.positions[i,0]-self.positions[self.obs_index,0])**2 +\n",
    "                                    (self.positions[i,1]-self.positions[self.obs_index,1])**2)\n",
    "        return distances\n",
    "        \n",
    "    def getParticlePositions(self):\n",
    "        return self.positions[:-1,:]\n",
    "    \n",
    "    def getObservationPosition(self):\n",
    "        return self.positions[-1, :]\n",
    "    \n",
    "    def getGaussianWeight(self, distance=None, normalize=True):\n",
    "        if distance is None:\n",
    "            distance = self.getDistances()\n",
    "        weights = (1.0/np.sqrt(2*np.pi*self.observation_gamma**2))* \\\n",
    "            np.exp(- (distance**2/(2*self.observation_gamma**2)))\n",
    "        if normalize:\n",
    "            return weights/np.sum(weights)\n",
    "        return weights\n",
    "    \n",
    "    \"\"\"\n",
    "    Weights are calculated using a Cauchy Distribution.\n",
    "    It is chosen over a Gauss distribution in order to obtain wider tails.\n",
    "    \"\"\"\n",
    "    def getCauchyWeight(self, distance=None, normalize=True):\n",
    "        if distance is None:\n",
    "            distance = self.getDistances()\n",
    "        weights = 1.0/(np.pi*self.observation_gamma*(1 + (distance/self.observation_gamma)**2))\n",
    "        if normalize:\n",
    "            return weights/np.sum(weights)\n",
    "        return weights    \n",
    "    \n",
    "    def plotDistanceInfo(self, title=None):\n",
    "        fig = plt.figure(figsize=(10,6))\n",
    "        gridspec.GridSpec(2, 3)\n",
    "        \n",
    "        # PLOT POSITIONS OF PARTICLES AND OBSERVATIONS\n",
    "        ax0 = plt.subplot2grid((2,3), (0,0))\n",
    "        plt.plot(self.getParticlePositions()[:,0], \\\n",
    "                 self.getParticlePositions()[:,1], 'b.')\n",
    "        plt.plot(self.getObservationPosition()[0], \\\n",
    "                 self.getObservationPosition()[1], 'r.')\n",
    "        plt.xlim(0, 1)\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.ylim(0, 1)\n",
    "        plt.title(\"Particle positions\")\n",
    "        \n",
    "        # PLOT DISCTRIBUTION OF PARTICLE DISTANCES AND THEORETIC OBSERVATION PDF\n",
    "        ax0 = plt.subplot2grid((2,3), (0,1), colspan=2)\n",
    "        distances = self.getDistances()\n",
    "        plt.hist(distances, bins=30, range=(0,1), normed=True, label=\"particle distances\")\n",
    "        \n",
    "        # With observation \n",
    "        x = np.linspace(0, 1.0, num=100)\n",
    "        cauchy_pdf = self.getCauchyWeight(x, normalize=False)\n",
    "        gauss_pdf = self.getGaussianWeight(x, normalize=False)\n",
    "        plt.plot(x, cauchy_pdf, 'r', label=\"obs Cauchy pdf\")\n",
    "        plt.plot(x, gauss_pdf, 'g', label=\"obs Gauss pdf\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Distribution of particle distances from observation\")\n",
    "        \n",
    "        # PLOT SORTED DISTANCES FROM OBSERVATION\n",
    "        ax0 = plt.subplot2grid((2,3), (1,0), colspan=3)\n",
    "        cauchyWeights = self.getCauchyWeight(distances)\n",
    "        gaussWeights = self.getGaussianWeight(distances)\n",
    "        indices_sorted_by_observation = distances.argsort()\n",
    "        plt.plot(distances[indices_sorted_by_observation], label=\"distance\")\n",
    "        plt.plot(cauchyWeights[indices_sorted_by_observation]/np.max(cauchyWeights), 'r', label=\"Cauchy weight\")\n",
    "        plt.plot(gaussWeights[indices_sorted_by_observation]/np.max(gaussWeights), 'g', label=\"Gauss weight\")\n",
    "        plt.title(\"Sorted distances from observation\")\n",
    "        plt.grid()\n",
    "        plt.ylim(0,1.4)\n",
    "        plt.legend()\n",
    "        if title is not None:\n",
    "            plt.suptitle(title)\n",
    "\n",
    "# Initialize an ensemble of particles:\n",
    "N = 1000\n",
    "globalParticles = GlobalParticles(N)\n",
    "globalParticles.initializeUnitSquare()\n",
    "\n",
    "# The particles are by now drawn from the prior distribution\n",
    "\n",
    "# Here, the simulation/time integration should take place\n",
    "\n",
    "# Inspect initial ensemble\n",
    "globalParticles.plotDistanceInfo(title=\"Initial particles\")\n",
    "print \"Observation: \", globalParticles.getObservationPosition()\n",
    "\n",
    "# Run particle filter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "globalParticles.plotDistanceInfo(title=\"Initial particles\")\n",
    "\n",
    "# Create a new GlobalParticles instance based on newSampleIndices\n",
    "def resampleParticles(particles, newSampleIndices):\n",
    "    newParticles = GlobalParticles(particles.numParticles)\n",
    "    \n",
    "    # Simply copy the given positions\n",
    "    newParticles.positions[:-1,:] = particles.positions[newSampleIndices,:].copy()\n",
    "    \n",
    "    # Copy the observation:\n",
    "    newParticles.positions[-1,:] = particles.positions[-1,:]\n",
    "    \n",
    "    return newParticles\n",
    "    \n",
    "\n",
    "def probabilisticResampling(particles):\n",
    "    # Obtain weights:\n",
    "    weights = particles.getGaussianWeight()\n",
    "    #weights = particles.getCauchyWeight()\n",
    "    \n",
    "    # Draw new indices based from discrete distribution based on weights\n",
    "    allIndices = range(particles.numParticles)\n",
    "    newSampleIndices = np.random.choice(allIndices, particles.numParticles, p=weights)\n",
    "        \n",
    "    # Return a new set of particles\n",
    "    return resampleParticles(particles, newSampleIndices)\n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "probabilisticResampledParticles = probabilisticResampling(globalParticles)\n",
    "probabilisticResampledParticles.plotDistanceInfo(title=\"From ProbabilisticResampling\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Sorting example from https://stackoverflow.com/a/21077060\n",
    "\n",
    "people = np.array(['Jim', 'Pam', 'Micheal', 'Dwight'])\n",
    "ages = np.array([27, 25, 4, 9])\n",
    "sorted_indices = ages.argsort()\n",
    "print people[sorted_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = 12312.12312\n",
    "print a % 1\n",
    "print np.floor(a)"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}