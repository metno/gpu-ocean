{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "This notebook sets up and runs a set of benchmarks to compare\n",
    "different numerical discretizations of the SWEs\n",
    "\n",
    "Copyright (C) 2016  SINTEF ICT\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rossby adjustment on different depths\n",
    "\n",
    "In this notebook we investigate different properties with our numerical schemes related to geostrophic balance when we vary the water depth. Geostrophic balance represent steady state solutions where the pressure gradients are balanced by the Coriolis forces.\n",
    "\n",
    "## Geostrophic Balance\n",
    "\n",
    "The geostrophic equations in rotating shalow water is given by\n",
    "$$ \\frac{\\partial u}{\\partial t} - fv  = - \\frac{1}{\\rho} \\frac{\\partial p}{\\partial x}, $$\n",
    "$$ \\frac{\\partial v}{\\partial t} + fu  = - \\frac{1}{\\rho} \\frac{\\partial p}{\\partial y}. $$\n",
    "By the assumption that the vertical velocity is negligible compared to the horizontal velocity, we integrate the equations vertically.\n",
    "Using hydrostatic pressure $ p = \\rho g (H+\\eta) + p_{atm}$, we get an expression for the change in momentum as\n",
    "$$ \\frac{\\partial hu}{\\partial t} =  fhv - gh\\frac{\\partial \\eta}{\\partial x}, $$\n",
    "$$ \\frac{\\partial hv}{\\partial t} = -fhu - gh\\frac{\\partial \\eta}{\\partial y}. $$\n",
    "At geostrophic balance, the steady state solution is described by $\\frac{\\partial hv}{\\partial t} = \\frac{\\partial hu}{\\partial t} = 0$.\n",
    "\n",
    "\n",
    "*What are the references for the above explanation?*\n",
    "\n",
    "###### Additional geostrophy equation\n",
    "The following equation is related to the above, to describe the steady-state of the surface elevation:\n",
    "$$\\frac{\\partial \\eta}{\\partial t} + hu\\frac{\\partial \\eta }{\\partial x } + hv \\frac{\\partial \\eta }{\\partial y} = 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rossby adjustment\n",
    "Rossby adjustment is the process where an initial bump (of some sort), $\\eta_0$, reaches the geostrophic balance steady-state $\\bar{\\eta}$. The size of the steady-state bump can be described by gravity\u00a0$g$, lake-at-rest depth\u00a0$H$ and Coriolis forces $f$ by the Klein-Gordon equation,\n",
    "$$ -c_0^2 \\nabla^2 \\bar{\\eta} + f^2 (\\bar{\\eta} - \\eta_0) = 0, $$\n",
    "or, more commonly (?),\n",
    "$$  \\nabla^2 \\bar{\\eta} -  \\left( \\frac{1}{a} \\right)^2 (\\bar{\\eta} - \\eta_0) = 0. $$\n",
    "In this equation, $(1/a)^2$\u00a0is the Rossby radius. The constant $c_0^2 = gH$, meaning that $a^2 = gH/f^2$. \n",
    "The physical interpretation of the Rossby radius, $a$, is shown in the first figure below the initial imports.\n",
    "\n",
    "Additionally, the steady-state solution should be reached within a period given by $\\approx \\pi/f$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying water depth\n",
    "\n",
    "The height of the steady state bump should change relative to the initial condition bump as follows when the depth is changed.\n",
    "* When the depth increase, $\\bar{\\eta}_{max}/{\\eta_0}_{max}$ should decrease\n",
    "* When the depth increase, $\\int\\bar{\\eta}\\;/\\int{\\eta_0}$ should increase.\n",
    "\n",
    "Here, $\\eta_0$ is the initial condition, and $\\bar{\\eta}$ is the steady state.\n",
    "The integral is the sum of $\\eta$ in all cells in a neighbourhood of the bump.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Lets have matplotlib \"inline\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "#Import packages we need\n",
    "import numpy as np\n",
    "from matplotlib import animation, rc\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec as gridspec\n",
    "\n",
    "import os, pyopencl, datetime, sys\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "# requires netcdf4-python (netcdf4-python.googlecode.com)\n",
    "from netCDF4 import Dataset as NetCDFFile\n",
    "\n",
    "#Finally, import our simulator\n",
    "from SWESimulators import FBL, CTCS, DataOutput\n",
    "\n",
    "#Set large figure sizes\n",
    "rc('figure', figsize=(16.0, 12.0))\n",
    "rc('animation', html='html5')\n",
    "\n",
    "#Finally, import our simulator\n",
    "from SWESimulators import FBL, CTCS, KP07, CDKLM16, RecursiveCDKLM16, DataOutput, SimWriter, PlotHelper, Common\n",
    "from SWESimulators.BathymetryAndICs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make sure we get compiler output from OpenCL\n",
    "os.environ[\"PYOPENCL_COMPILER_OUTPUT\"] = \"1\"\n",
    "\n",
    "#Set which CL device to use, and disable kernel caching\n",
    "if (str.lower(sys.platform).startswith(\"linux\")):\n",
    "    os.environ[\"PYOPENCL_CTX\"] = \"0\"\n",
    "else:\n",
    "    os.environ[\"PYOPENCL_CTX\"] = \"1\"\n",
    "os.environ[\"CUDA_CACHE_DISABLE\"] = \"1\"\n",
    "os.environ[\"PYOPENCL_COMPILER_OUTPUT\"] = \"1\"\n",
    "os.environ[\"PYOPENCL_NO_CACHE\"] = \"1\"\n",
    "\n",
    "#Create OpenCL context\n",
    "cl_ctx = pyopencl.create_some_context()\n",
    "print \"Using \", cl_ctx.devices[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create output directory for images\n",
    "imgdir='images_' + datetime.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "os.makedirs(imgdir)\n",
    "print \"Saving images to \" + imgdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected results, as explained by G\u00f6ran in early nov(?) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Qualitatively expected results:\n",
    "def qualitativExpectedResults():\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    depth = np.array(range(100,5100, 500))\n",
    "    max_height = 2 + np.cos(depth*np.pi/5100)\n",
    "    integrals = 2 - np.cos(depth*np.pi/5100)\n",
    "    \n",
    "    plt.plot(max_height, 'b', label=\"relative $\\eta_{max}$\")\n",
    "    plt.plot(integrals,   'r', label=\"relative integral$(\\eta)$\")\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0.7, 4])\n",
    "    plt.legend()\n",
    "qualitativExpectedResults()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting common parameters\n",
    "\n",
    "Below are two different sets of parameters. Those from Kai describe a larger (but maybe more realistic) test case, compared to those by H\u00e5vard, which are cheaper to run.\n",
    "\n",
    "In order to activate one or the other, change the cell type of the one you would like to run to \"Code\", and the other to \"Markdown\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Common parameters from Kai\n",
    "\n",
    "nx = 800\n",
    "ny = 1000\n",
    "\n",
    "dx = 50000\n",
    "dy = 50000\n",
    "\n",
    "dt = 100\n",
    "g = 9.81\n",
    "f = 1.2e-4\n",
    "r = 0.0\n",
    "multi_H0 = np.array(range(100, 5200, 500))*1.0\n",
    "print(multi_H0)\n",
    "A = 0.0 # A is diffusion coefficient multiplied by depth.\n",
    "\n",
    "wind = Common.WindStressParams(type=99)\n",
    "\n",
    "## Setting up boundary conditions\n",
    "sponge = [10, 10, 10, 10]\n",
    "boundaryConditions = Common.BoundaryConditions(3,3,3,3, spongeCells=sponge)\n",
    "\n",
    "ghosts = [10, 10, 10, 10]\n",
    "dataShape = (ny + ghosts[0]+ghosts[2], \n",
    "             nx + ghosts[1]+ghosts[3])\n",
    "validDomain =  [10, 10, 10, 10]\n",
    "\n",
    "geoBalancePlot = True\n",
    "\n",
    "T = 40\n",
    "sub_T = 2*600*dt\n",
    "make_netCDF = True\n",
    "\n",
    "# For plotting:\n",
    "#Calculate radius from center of bump for plotting\n",
    "x_center = dx*nx/2.0\n",
    "y_center = dy*ny/2.0\n",
    "y_coords, x_coords = np.mgrid[0:ny*dy:dy, 0:nx*dx:dx]\n",
    "x_coords = np.subtract(x_coords, x_center)\n",
    "y_coords = np.subtract(y_coords, y_center)\n",
    "radius = np.sqrt(np.multiply(x_coords, x_coords) + np.multiply(y_coords, y_coords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setUpInitialStructure(file_name):\n",
    "    git_hash = str.strip(subprocess.check_output(['git', 'rev-parse', 'HEAD']))\n",
    "\n",
    "    main_data = {'git_hash': git_hash, \\\n",
    "                 'FBL':   [],  \\\n",
    "                 'CTCS':  [],  \\\n",
    "                 'KP07':  [],  \\\n",
    "                 'CDKLM': [],  \\\n",
    "                 'timestamp': datetime.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\"), \\\n",
    "                 'GPU': cl_ctx.devices[0].name}\n",
    "    \n",
    "    with open(file_name, 'w') as fout:\n",
    "        json.dump(main_data, fout)\n",
    "        \n",
    "def addResults(file_name, sim_name, netcdf_name, depth, eta_max, eta_init_max, T_end, dt):\n",
    "    \n",
    "    sim_data = {'sim_name': sim_name, 'netcdf_file_name': netcdf_name, \\\n",
    "                'depth': float(depth), 'eta_max': float(eta_max), 'eta_init_max': float(eta_init_max), \\\n",
    "                'T_end': float(T_end), 'dt': float(dt)}\n",
    "    with open(file_name, mode='r+') as json_file:\n",
    "        json_element =  json.load(json_file)\n",
    "        json_file.seek(0)\n",
    "        #print json_element\n",
    "        json_element[sim_name].append(sim_data)\n",
    "        #print json_element\n",
    "        json.dump(json_element, json_file)\n",
    "    \n",
    "    print \"Wrote \" + sim_name + \" with H0=\"+str(depth) + \" to json\"\n",
    "    print \"Relative eta_max/eta_init_max: \", eta_max/eta_init_max\n",
    "    print \"(dt, T_end): \", (dt, T_end)\n",
    "    print \"------------------------------\"\n",
    "\n",
    "\n",
    "jsondir = \"rossbyAdjustmentResults/\"\n",
    "json_file_name = jsondir + \"all_simulators_\" + datetime.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")  +\".json\"\n",
    "setUpInitialStructure(json_file_name)\n",
    "print json_file_name\n",
    "#json_file_name = jsondir + \"all_simulators_2018_01_25-13_10_27.json\"\n",
    "#addResults(json_file_name, 'CTCS', 'netcfd_NaMe', 10, 1, 2, 100000, 0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating initial conditions\n",
    "\n",
    "Staggered and unstaggered grids are placed so that cell centers are on the same place. Keep therefore in mind that the velocities are defined at different positions for the two different grid types!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def initialConditions(eta0, nx, ny, dx, dy, halo_x, halo_y):\n",
    "    print \"Making initial conditions\"\n",
    "    x_center = dx*nx/2.0\n",
    "    y_center = dy*ny/2.0\n",
    "    y_center1 = dy*(ny-100)/2.0\n",
    "    y_center2 = dy*(ny+100)/2.0\n",
    "\n",
    "    for j in range(-halo_y, ny+halo_y):\n",
    "        for i in range(-halo_x, nx+halo_x):\n",
    "            x = dx*i - x_center \n",
    "            y = dy*j - y_center \n",
    "            y1 = dy*j - y_center1\n",
    "            y2 = dy*j - y_center2\n",
    "\n",
    "            # Initial smooth step\n",
    "            inirad = np.sqrt(x**2 + y**2)\n",
    "            inirad1 = np.sqrt(x**2 + y1**2)\n",
    "            inirad2 = np.sqrt(x**2 + y2**2)\n",
    "            L = 15*dx\n",
    "            D = 50*dx\n",
    "            etaamp = 0.2\n",
    "            \n",
    "            # Add the the initial condition to the provided array\n",
    "            #eta0[j+1, i+1] += 0.5*etaamp*(1.0+np.tanh((-inirad+D)/L))\n",
    "            eta0[j+halo_y, i+halo_x] += 0.5*etaamp*(1.0+np.tanh((-inirad+D)/L))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the \"steady state\"ness of the solution by looking at Klein-Gordon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns d/dx(0.5*g*h*h) + fhv\n",
    "\"\"\"\n",
    "def geostrophicBalanceEta(eta, H, hu, hv, nx, ny, dx, dy, f, g):\n",
    "    return geostrophicBalance(eta+H, hu, hv, nx, ny, dx, dy, f, g)\n",
    "\n",
    "def geostrophicBalance(h, hu, hv, nx, ny, dx, dy, f, g):\n",
    "    # Expect 0 ghost cells in input arrays\n",
    "    A = hu*hv/h\n",
    "    B = hu*hu/h\n",
    "    C = 0.5*g*h*h\n",
    "    D = -f*hv\n",
    "    \n",
    "    Ay = np.zeros_like(A)\n",
    "    Bx = np.zeros_like(B)\n",
    "    Cx = np.zeros_like(C)\n",
    "    \n",
    "    Ay[1:-1,:] = (A[:-2,:] - A[2:,:])/(2*dy)\n",
    "    Bx[:, 1:-1] = (B[:,:-2] - B[:,2:])/(2*dx)\n",
    "    Cx[:, 1:-1] = (C[:,:-2] - C[:,2:])/(2*dx)\n",
    "    \n",
    "    #geoBalance = (Cx )/D - 1\n",
    "    geoBalance = Cx - D\n",
    "    #geoBalance = (Ay + Bx + Cx )/D - 1\n",
    "    #geoBalance = (Ay + Bx + Cx - D)/(0.5*(Ay + Bx + Cx + D))\n",
    "    return geoBalance\n",
    "\n",
    "def geostrophicBalanceStaggered(eta, H, hu_s, hv_s, nx, ny, dx, dy, f, g):\n",
    "    # Expect 0 ghost cells only\n",
    "       \n",
    "    h = eta + H\n",
    "    hu = 0.5*(hu_s[:, :-1] + hu_s[:, 1:])\n",
    "    hv = 0.5*(hv_s[:-1, :] + hv_s[1:, :])\n",
    "    return geostrophicBalance(h, hu, hv, nx, ny, dx, dy, f, g )\n",
    "\n",
    "## Here, we assume that ghost cells are a part of the picture, and that there are 10 in all direction\n",
    "def evaluateBalance(eta_tot, hu_tot, hv_tot, H0_tot):\n",
    "    staggered = not (eta_tot.shape == hu_tot.shape)\n",
    "    eta = eta_tot[10:-10, 10:-10]\n",
    "    H   =  H0_tot[10:-10, 10:-10]\n",
    "    hu  =  hu_tot[10:-10, 10:-10]\n",
    "    hv  =  hv_tot[10:-10, 10:-10]\n",
    "    if staggered:\n",
    "        geoBalance_x = geostrophicBalanceStaggered(eta,   H,   hu,   hv,   nx, ny, dx, dy, f, g)\n",
    "        geoBalance_y = geostrophicBalanceStaggered(eta.T, H.T, hv.T, hu.T, nx, ny, dx, dy, f, g)\n",
    "    else:\n",
    "        geoBalance_x = geostrophicBalanceEta(eta,   H,   hu,   hv,   nx, ny, dx, dy, f, g)\n",
    "        geoBalance_y = geostrophicBalanceEta(eta.T, H.T, hv.T, hu.T, nx, ny, dx, dy, f, g)\n",
    "    print \"max geobalances - (x,y): \", (np.max(geoBalance_x), np.max(geoBalance_y))\n",
    "\n",
    "    if geoBalancePlot:\n",
    "        fig = plt.figure(figsize=(10, 4))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(geoBalance_x, interpolation=\"none\", origin='lower')\n",
    "        plt.title(\"x-direction\")\n",
    "        plt.colorbar()\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(geoBalance_y.T, interpolation=\"none\", origin='lower')\n",
    "        plt.title(\"y-direction\")\n",
    "        plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing simulators\n",
    "\n",
    "A single test of CTCS to look at the parameters above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping over different depth values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Forward-Backward-Linear \n",
    "\n",
    "reload(FBL)\n",
    "\n",
    "fbl_eta0 = np.zeros(dataShape, dtype=np.float32, order='C');\n",
    "initialConditions(fbl_eta0, nx, ny, dx, dy, ghosts[1], ghosts[0])\n",
    "\n",
    "fbl_u0 = np.zeros((dataShape[0], dataShape[1]+1), dtype=np.float32, order='C');\n",
    "fbl_v0 = np.zeros((dataShape[0]+1, dataShape[1]), dtype=np.float32, order='C');\n",
    "\n",
    "fbl_dt = dt\n",
    "fbl_sub_T = sub_T\n",
    "\n",
    "# Bathymetry:\n",
    "Bi = np.zeros((dataShape[0]+1, dataShape[1]+1), dtype=np.float32, order='C')\n",
    "\n",
    "for i in range(len(multi_H0)):\n",
    "    H0 = multi_H0[i]\n",
    "\n",
    "    fbl_h0 = np.ones(dataShape, dtype=np.float32, order='C') * H0;\n",
    "    if H0 == 600:\n",
    "        fbl_sub_T = fbl_sub_T/2\n",
    "    if H0 == 1600:\n",
    "        fbl_sub_T = fbl_sub_T/2\n",
    "    if H0 == 3600:\n",
    "        fbl_dt = fbl_dt/2\n",
    "        fbl_sub_T = fbl_sub_T/2\n",
    "    if H0 == 4600:\n",
    "        fbl_dt = fbl_dt/2\n",
    "        \n",
    "    #Initialize simulator\n",
    "    fbl_sim = FBL.FBL(cl_ctx, \\\n",
    "                      fbl_h0, fbl_eta0, fbl_u0, fbl_v0, \\\n",
    "                      nx, ny, \\\n",
    "                      dx, dy, fbl_dt, \\\n",
    "                      g, f, r, \\\n",
    "                      wind_stress=wind, \\\n",
    "                      boundary_conditions=boundaryConditions, \\\n",
    "                      write_netcdf=make_netCDF\n",
    "                     )\n",
    "\n",
    "    print \"Starting FBL with H0 = \" + str(H0)\n",
    "    \n",
    "    t = fbl_sim.step(T*fbl_sub_T)\n",
    "\n",
    "    # Computing the interesting values:    \n",
    "    fbl_eta1, u1, v1 = fbl_sim.download()\n",
    "    #evaluateBalance(fbl_eta1, u1, v1, fbl_h0)\n",
    "    fbl_sim.cleanUp()\n",
    "    \n",
    "    eta_max = np.max(fbl_eta1)\n",
    "    eta_init_max = np.max(fbl_eta0)\n",
    "        \n",
    "    addResults(json_file_name, \"FBL\", fbl_sim.sim_writer.output_file_name, H0, eta_max, eta_init_max, t, fbl_dt) \n",
    "    \n",
    "    fbl_h0 = None\n",
    "    fbl_eta1, u1, v1 = None, None, None\n",
    "    #if 'fbl_sim' in globals():\n",
    "    #    fbl_sim.cleanUp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Centered-in-Time, Centered-in-space\n",
    "\n",
    "reload(CTCS)\n",
    "\n",
    "ctcs_eta0 = np.zeros(dataShape, dtype=np.float32, order='C');\n",
    "initialConditions(ctcs_eta0, nx, ny, dx, dy, ghosts[1], ghosts[0])\n",
    "\n",
    "ctcs_u0 = np.zeros((dataShape[0], dataShape[1]+1), dtype=np.float32, order='C');\n",
    "ctcs_v0 = np.zeros((dataShape[0]+1, dataShape[1]), dtype=np.float32, order='C');\n",
    "\n",
    "ctcs_dt = dt\n",
    "ctcs_sub_T = sub_T\n",
    "\n",
    "# Bathymetry:\n",
    "Bi = np.zeros((dataShape[0]+1, dataShape[1]+1), dtype=np.float32, order='C')\n",
    "\n",
    "for i in range(len(multi_H0)):\n",
    "    H0 = multi_H0[i]\n",
    "\n",
    "    ctcs_h0 = np.ones(dataShape, dtype=np.float32, order='C') * H0;\n",
    "    if H0 == 600:\n",
    "        ctcs_sub_T = ctcs_sub_T/2\n",
    "    if H0 == 1600:\n",
    "        ctcs_sub_T = ctcs_sub_T/2\n",
    "    if H0 == 3600:\n",
    "        ctcs_dt = ctcs_dt/2\n",
    "        ctcs_sub_T = ctcs_sub_T/2\n",
    "    if H0 == 4600:\n",
    "        ctcs_dt = ctcs_dt/2\n",
    "        \n",
    "    #Initialize simulator\n",
    "    ctcs_sim = CTCS.CTCS(cl_ctx, \\\n",
    "                         ctcs_h0, ctcs_eta0, ctcs_u0, ctcs_v0, \\\n",
    "                         nx, ny, \\\n",
    "                         dx, dy, ctcs_dt, \\\n",
    "                         g, f, r, A, \\\n",
    "                         wind_stress=wind, \\\n",
    "                         boundary_conditions=boundaryConditions, \\\n",
    "                         write_netcdf=make_netCDF\n",
    "                        )\n",
    "\n",
    "    print \"Starting CTCS with H0 = \" + str(H0)\n",
    "    \n",
    "    t = ctcs_sim.step(T*ctcs_sub_T)\n",
    "\n",
    "    # Computing the interesting values:    \n",
    "    ctcs_eta1, u1, v1 = ctcs_sim.download()\n",
    "    #evaluateBalance(ctcs_eta1, u1, v1, ctcs_h0)\n",
    "    ctcs_sim.cleanUp()\n",
    "    \n",
    "    eta_max = np.max(ctcs_eta1)\n",
    "    eta_init_max = np.max(ctcs_eta0)\n",
    "        \n",
    "    addResults(json_file_name, \"CTCS\", ctcs_sim.sim_writer.output_file_name, H0, eta_max, eta_init_max, t, ctcs_dt) \n",
    "    \n",
    "    ctcs_h0 = None\n",
    "    ctcs_eta1, u1, v1 = None, None, None\n",
    "    #if 'ctcs_sim' in globals():\n",
    "    #    ctcs_sim.cleanUp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Kurganov-Petrova 2007\n",
    "\n",
    "reload(KP07)\n",
    "\n",
    "kp07_eta0 = np.zeros(dataShape, dtype=np.float32, order='C');\n",
    "initialConditions(kp07_eta0, nx, ny, dx, dy, ghosts[1], ghosts[0])\n",
    "\n",
    "kp07_u0 = np.zeros((dataShape[0], dataShape[1]), dtype=np.float32, order='C');\n",
    "kp07_v0 = np.zeros((dataShape[0], dataShape[1]), dtype=np.float32, order='C');\n",
    "\n",
    "kp07_dt = dt\n",
    "kp07_sub_T = sub_T\n",
    "\n",
    "\n",
    "for i in range(len(multi_H0)):\n",
    "    H0 = multi_H0[i]\n",
    "\n",
    "    kp07_h0 = np.ones((dataShape[0]+1, dataShape[1]+1), dtype=np.float32, order='C') * H0;\n",
    "    if H0 == 600:\n",
    "        kp07_sub_T = kp07_sub_T/2\n",
    "    if H0 == 1600:\n",
    "        kp07_sub_T = kp07_sub_T/2\n",
    "    if H0 == 3600:\n",
    "        kp07_dt = kp07_dt/2\n",
    "        kp07_sub_T = kp07_sub_T/2\n",
    "    if H0 == 4600:\n",
    "        kp07_dt = kp07_dt/2\n",
    "        \n",
    "    #Initialize simulator\n",
    "    kp07_sim = KP07.KP07(cl_ctx, \\\n",
    "                         kp07_eta0, kp07_h0, kp07_u0, kp07_v0, \\\n",
    "                         nx, ny, \\\n",
    "                         dx, dy, kp07_dt, \\\n",
    "                         g, f, r, \\\n",
    "                         wind_stress=wind, \\\n",
    "                         boundary_conditions=boundaryConditions, \\\n",
    "                         write_netcdf=make_netCDF\n",
    "                        )\n",
    "\n",
    "    print \"Starting KP07 with H0 = \" + str(H0)\n",
    "    \n",
    "    t = kp07_sim.step(T*kp07_sub_T)\n",
    "\n",
    "    # Computing the interesting values:    \n",
    "    kp07_eta1, u1, v1 = kp07_sim.download()\n",
    "    #evaluateBalance(kp07_eta1, u1, v1, kp07_h0)\n",
    "    kp07_sim.cleanUp()\n",
    "    \n",
    "    eta_max = np.max(kp07_eta1)\n",
    "    eta_init_max = np.max(kp07_eta0)\n",
    "        \n",
    "    addResults(json_file_name, \"KP07\", kp07_sim.sim_writer.output_file_name, H0, eta_max, eta_init_max, t, kp07_dt) \n",
    "    \n",
    "    kp07_h0 = None\n",
    "    kp07_eta1, u1, v1 = None, None, None\n",
    "    #if 'kp07_sim' in globals():\n",
    "    #    kp07_sim.cleanUp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# CDKLM16\n",
    "\n",
    "reload(CDKLM16)\n",
    "\n",
    "cdklm_eta0 = np.zeros(dataShape, dtype=np.float32, order='C');\n",
    "initialConditions(cdklm_eta0, nx, ny, dx, dy, ghosts[1], ghosts[0])\n",
    "\n",
    "cdklm_u0 = np.zeros((dataShape[0], dataShape[1]), dtype=np.float32, order='C');\n",
    "cdklm_v0 = np.zeros((dataShape[0], dataShape[1]), dtype=np.float32, order='C');\n",
    "\n",
    "cdklm_dt = dt\n",
    "cdklm_sub_T = sub_T\n",
    "\n",
    "for i in range(len(multi_H0)):\n",
    "    H0 = multi_H0[i]\n",
    "\n",
    "    cdklm_h0 = np.ones((dataShape[0]+1, dataShape[1]+1), dtype=np.float32, order='C') * H0;\n",
    "    if H0 == 600:\n",
    "        cdklm_sub_T = cdklm_sub_T/2\n",
    "    if H0 == 1600:\n",
    "        cdklm_sub_T = cdklm_sub_T/2\n",
    "    if H0 == 3600:\n",
    "        cdklm_dt = cdklm_dt/2\n",
    "        cdklm_sub_T = cdklm_sub_T/2\n",
    "    if H0 == 4600:\n",
    "        cdklm_dt = cdklm_dt/2\n",
    "        \n",
    "    #Initialize simulator\n",
    "    cdklm_sim = CDKLM16.CDKLM16(cl_ctx, \\\n",
    "                         cdklm_eta0, cdklm_u0, cdklm_v0, cdklm_h0, \\\n",
    "                         nx, ny, \\\n",
    "                         dx, dy, cdklm_dt, \\\n",
    "                         g, f, r, \\\n",
    "                         wind_stress=wind, \\\n",
    "                         boundary_conditions=boundaryConditions, \\\n",
    "                         write_netcdf=make_netCDF\n",
    "                        )\n",
    "\n",
    "    print \"Starting CDKLM16 with H0 = \" + str(H0)\n",
    "    \n",
    "    t = cdklm_sim.step(T*cdklm_sub_T)\n",
    "\n",
    "    # Computing the interesting values:    \n",
    "    cdklm_eta1, u1, v1 = cdklm_sim.download()\n",
    "    #evaluateBalance(cdklm_eta1, u1, v1, cdklm_h0)\n",
    "    cdklm_sim.cleanUp()\n",
    "    \n",
    "    eta_max = np.max(cdklm_eta1)\n",
    "    eta_init_max = np.max(cdklm_eta0)\n",
    "        \n",
    "    addResults(json_file_name, \"CDKLM\", cdklm_sim.sim_writer.output_file_name, H0, eta_max, eta_init_max, t, cdklm_dt) \n",
    "    \n",
    "    cdklm_h0 = None\n",
    "    cdklm_eta1, u1, v1 = None, None, None\n",
    "    #if 'cdklm_sim' in globals():\n",
    "    #    cdklm_sim.cleanUp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Make nice G\u00f6ran plots!\n",
    "print multi_H0.shape, ctcs_relInts.shape, ctcs_relMax.shape\n",
    "\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "plt.plot(multi_H0, ctcs_relInts)\n",
    "plt.title(\"CTCS - relative integrals\")\n",
    "plt.xlabel(\"depth\")\n",
    "\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "plt.plot(multi_H0, ctcs_relMax)\n",
    "plt.title(\"CTCS - relative max height\")\n",
    "plt.xlabel(\"depth\")\n",
    "\n",
    "#= sum(sum(cdklm_eta)) / sum(sum(cdklm_eta0))\n",
    "#    cdklm_relMax[i])"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}