{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "This software is a part of GPU Ocean.\n",
    "\n",
    "Copyright (C) 2019  SINTEF Digital\n",
    "\n",
    "Notebook that investigate the weight distribution through the ensemble\n",
    "when using the basic particle filter with Sequential Importance \n",
    "Resampling (SIR).\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIR Particle Filter\n",
    "\n",
    "Notebook that investigate the weight distribution through the ensemble\n",
    "when using the basic particle filter with Sequential Importance \n",
    "Resampling (SIR)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "\n",
    "import pycuda.driver as cuda\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from importlib import reload\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../../')))\n",
    "\n",
    "#Set large figure sizes\n",
    "rc('figure', figsize=(16.0, 12.0))\n",
    "rc('animation', html='html5')\n",
    "\n",
    "#Import our simulator\n",
    "from SWESimulators import IPythonMagic, SimReader, Observation, CDKLM16, IEWPFOcean\n",
    "from SWESimulators import EnsembleFromFiles\n",
    "from SWESimulators import DataAssimilationUtils as dautils\n",
    "from SWESimulators import EnsemblePlot as ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cuda_context_handler gpu_ctx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_init_path = os.path.abspath('presented_data/ensemble_init/')\n",
    "assert len(os.listdir(ensemble_init_path)) == 100 or len(os.listdir(ensemble_init_path)) == 101, \\\n",
    "    \"Ensemble init folder has wrong number of files\"\n",
    "\n",
    "truth_path = os.path.abspath('presented_data/true_state/')\n",
    "assert len(os.listdir(truth_path)) == 2 or len(os.listdir(truth_path)) == 3, \"Truth folder has wrong number of files\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(im, interpolation=\"None\", title=None, figsize=(4,4), interior=False):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    \n",
    "    if interior:\n",
    "        im = plt.imshow(im[2:-2,2:-2], interpolation=interpolation, origin='lower')\n",
    "    else:\n",
    "        im = plt.imshow(im, interpolation=interpolation, origin='lower')\n",
    "    \n",
    "    plt.colorbar()\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "        \n",
    "def imshow3(eta, hu, hv, interpolation=\"None\", title=None, figsize=(12,3), \n",
    "            interior=False, color_bar_from_zero=False):\n",
    "    fig, axs = plt.subplots(1,3, figsize=figsize)\n",
    "    \n",
    "    eta_max = np.max(np.abs(eta))\n",
    "    huv_max = max(np.max(np.abs(hu)), np.max(np.abs(hv)))\n",
    "    eta_min = -eta_max\n",
    "    huv_min = -huv_max\n",
    "    if color_bar_from_zero:\n",
    "        eta_min, huv_min = 0, 0\n",
    "    \n",
    "    if interior:\n",
    "        eta_im = axs[0].imshow(eta[2:-2,2:-2], interpolation=interpolation, origin='lower', vmin=eta_min, vmax=eta_max)\n",
    "    else:\n",
    "        eta_im = axs[0].imshow(eta, interpolation=interpolation, origin='lower', vmin=eta_min, vmax=eta_max)\n",
    "    axs[0].set_title(\"$\\eta$\")\n",
    "    plt.colorbar(eta_im, ax=axs[0])\n",
    "    \n",
    "    if interior:\n",
    "        hu_im = axs[1].imshow(hu[2:-2,2:-2], interpolation=interpolation, origin='lower', vmin=huv_min, vmax=huv_max)\n",
    "    else:\n",
    "        hu_im = axs[1].imshow(hu, interpolation=interpolation, origin='lower', vmin=huv_min, vmax=huv_max)\n",
    "    axs[1].set_title(\"$hu$\")\n",
    "    plt.colorbar(hu_im, ax=axs[1])\n",
    "\n",
    "    if interior:\n",
    "        hv_im = axs[2].imshow(hv[2:-2,2:-2], interpolation=interpolation, origin='lower', vmin=huv_min, vmax=huv_max)\n",
    "    else:\n",
    "        hv_im = axs[2].imshow(hv, interpolation=interpolation, origin='lower', vmin=huv_min, vmax=huv_max)\n",
    "    axs[2].set_title(\"$hv$\")\n",
    "    plt.colorbar(hv_im, ax=axs[2])\n",
    "\n",
    "    if title is not None:\n",
    "        plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "def plotDrifters(observations, sim_reader, t, drifter_set=[]):\n",
    "    drifter_positions = observations.get_drifter_position(t)\n",
    "\n",
    "    fig = plt.figure(figsize=(7,7))\n",
    "    ax = plt.subplot(111)\n",
    "    nx, ny = sim_reader.get('nx'), sim_reader.get('ny')\n",
    "    dx, dy = sim_reader.get('dx'), sim_reader.get('dy')\n",
    "\n",
    "    emptyData =np.ma.masked_where(np.zeros((ny,nx)) > 1, np.zeros((ny,nx)))\n",
    "    ax.imshow(emptyData, origin=\"lower\", extent=[0, nx*dx, 0, ny*dy], cmap='binary')\n",
    "\n",
    "    for i in range(drifter_positions.shape[0]):\n",
    "        color = 'xkcd:pale cyan'\n",
    "        if i in drifter_set:\n",
    "            color = 'xkcd:tomato red'\n",
    "        circ_end = matplotlib.patches.Circle((drifter_positions[i,0], drifter_positions[i,1]),\n",
    "                                             3000, fill=True, zorder=10, color=color)\n",
    "        ax.add_patch(circ_end)\n",
    "\n",
    "    \n",
    "def days_to_sec(days):\n",
    "    return days*24*60*60\n",
    "\n",
    "def truth_time_step(t):\n",
    "    t = t - days_to_sec(3)\n",
    "    return int(t/(60*60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_drifter_set(num_drifters):\n",
    "    all_drifters = np.arange(64)\n",
    "    stepsize = 64/num_drifters\n",
    "    drifter_set = all_drifters[(np.arange(num_drifters)*stepsize).astype(int)]\n",
    "    return list(drifter_set)\n",
    "\n",
    "get_drifter_set(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ensemble_args = {'gpu_ctx': gpu_ctx,\n",
    "                 'numParticles': 100,\n",
    "                 'ensemble_directory': ensemble_init_path,\n",
    "                 'true_state_directory': truth_path,\n",
    "                 'observation_variance': 1.0,\n",
    "                 'cont_write_netcdf': False,\n",
    "                 'use_lcg': True,\n",
    "                 #write_netcdf_directory = None,\n",
    "                 'observation_type': dautils.ObservationType.UnderlyingFlow,\n",
    "                 #'observation_type': dautils.ObservationType.StaticBuoys,\n",
    "                 'randomize_initial_ensemble': False,\n",
    "                 'compensate_for_eta': True\n",
    "                }\n",
    "        \n",
    "#drifterSet = [ 2,  7, 12, 24, 29, 35, 41, 48, 53, 60]\n",
    "num_drifters = 64\n",
    "drifterSet = get_drifter_set(num_drifters)\n",
    "if len(drifterSet) < 10:\n",
    "    print('drifterSet: ', drifterSet)\n",
    "\n",
    "#Clean up old ensemble if any:\n",
    "if 'ensemble' in globals():\n",
    "    ensemble.cleanUp()\n",
    "\n",
    "print('generating ensemble of size ' + str(ensemble_args['numParticles']))\n",
    "ensemble = EnsembleFromFiles.EnsembleFromFiles(**ensemble_args)\n",
    "\n",
    "# Configure observations according to the selected drifters:\n",
    "ensemble.configureObservations(drifterSet=drifterSet)\n",
    "\n",
    "\n",
    "\n",
    "print('ensemble ready')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obstime = 3*24*60*60\n",
    "obstime += 5*60\n",
    "ensemble.stepToObservation(obstime, model_error_final_step=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "innovations = ensemble.getInnovations()\n",
    "innovations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_obstime_ep = ep.plotDistanceInfo(ensemble)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "iewpf = IEWPFOcean.IEWPFOcean(ensemble)\n",
    "\n",
    "numDays = 3\n",
    "numHours = 24\n",
    "\n",
    "master_tic = time.time()\n",
    "for day in range(numDays):\n",
    "    print('-------- Starting day ' + str(day))\n",
    "\n",
    "    for hour in range(numHours):\n",
    "\n",
    "        for fiveMin in range(12):\n",
    "            \n",
    "            if (day == 0) and (hour == 0) and (fiveMin == 0):\n",
    "                iewpf.iewpf_2stage(ensemble, perform_step=False)\n",
    "                continue\n",
    "            \n",
    "            #drifter_cells = ensemble.getDrifterCells()\n",
    "\n",
    "            for minute in range(5):\n",
    "                obstime += 60\n",
    "                ensemble.stepToObservation(obstime, model_error_final_step=(minute<4))\n",
    "\n",
    "                if minute == 4:\n",
    "                    iewpf.iewpf_2stage(ensemble, perform_step=False)\n",
    "\n",
    "                #ensemble.registerStateSample(drifter_cells)\n",
    "            print('.'+str(fiveMin*5)+'.', end='')\n",
    "            # Done minutes\n",
    "\n",
    "        # Done five minutes\n",
    "\n",
    "        toc = time.time()\n",
    "        print(\"\\n{:04.1f} s: \".format(toc-master_tic) + \" Done simulating hour \" + str(hour + 1) + \" of day \" + str(day + 3))\n",
    "    # Done hours\n",
    "# Done day\n",
    "\n",
    "print('Ready for weight calculation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_analysis = ensemble.getGaussianWeight(normalize=True, R_scale=1)\n",
    "weights_analysis.sort()\n",
    "for i in range(1,11):\n",
    "    print(\"{:02.4f}%\".format(weights_analysis[-i]*100))\n",
    "num_above_1_percent = sum(weights_analysis > 0.01)\n",
    "print(\"Number of particles with weight > 1%: \" + str(num_above_1_percent))\n",
    "print(\"Total weight on < 1%: \" + str(1-sum(weights_analysis[-num_above_1_percent:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_analysis = ep.plotDistanceInfo(ensemble)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obstime += 5*60\n",
    "ensemble.stepToObservation(obstime, model_error_final_step=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_forecast = ensemble.getGaussianWeight(normalize=True, R_scale=1)\n",
    "weights_forecast.sort()\n",
    "for i in range(1,11):\n",
    "    print(\"{:02.4f}%\".format(weights_forecast[-i]*100) )\n",
    "num_above_1_percent = sum(weights_forecast > 0.01)\n",
    "print(\"Number of particles with weight > 1%: \" + str(num_above_1_percent))\n",
    "print(\"Total weight on < 1%: \" + str(1-sum(weights_forecast[-num_above_1_percent:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_forecast = ep.plotDistanceInfo(ensemble)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_innovations = ensemble.getInnovations()\n",
    "all_innovations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drifters = np.arange(64)\n",
    "selected_drifters = np.random.choice(drifters, size=40, replace=False)\n",
    "selected_drifters.sort()\n",
    "selected_drifters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_formatter = lambda x: \"%.5f\" % x\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drifterSet = np.arange(64, dtype=np.int32)\n",
    "\n",
    "mean_particles_above_1_percent = np.zeros(64)\n",
    "mean_particles_above_1_percent_10R = np.zeros(64)\n",
    "mean_particles_above_1_percent_50R = np.zeros(64)\n",
    "\n",
    "for drifter_set_size in range(1,64):\n",
    "\n",
    "    print(\"-------- drifterSet length: \" + str(drifter_set_size) + \" -------\")\n",
    "    \n",
    "    iterations_per_size = 50\n",
    "    best_weights = np.zeros((10, iterations_per_size))\n",
    "    num_above_1_percent     = np.zeros(iterations_per_size, dtype=np.int32)\n",
    "    num_above_1_percent_10R = np.zeros(iterations_per_size, dtype=np.int32)\n",
    "    num_above_1_percent_50R = np.zeros(iterations_per_size, dtype=np.int32)\n",
    "    leftover_weight = np.zeros(iterations_per_size)\n",
    "    \n",
    "    for i in range(iterations_per_size):\n",
    "        selected_drifters = np.random.choice(drifters, size=drifter_set_size, replace=False)\n",
    "        selected_drifters.sort()\n",
    "        innovations = all_innovations[:,selected_drifters,:]\n",
    "    \n",
    "        weights_forecast     = ensemble.getGaussianWeight(normalize=True, R_scale=1,  \\\n",
    "                                                          innovations=innovations)\n",
    "        weights_forecast_10R = ensemble.getGaussianWeight(normalize=True, R_scale=10, \\\n",
    "                                                          innovations=innovations)\n",
    "        weights_forecast_50R = ensemble.getGaussianWeight(normalize=True, R_scale=50, \\\n",
    "                                                          innovations=innovations)\n",
    "        weights_forecast.sort()\n",
    "        weights_forecast = weights_forecast[::-1]\n",
    "        best_weights[:, i] = weights_forecast[:10]\n",
    "        \n",
    "        num_above_1_percent[i]     = sum(weights_forecast > 0.01)\n",
    "        num_above_1_percent_10R[i] = sum(weights_forecast_10R > 0.01)\n",
    "        num_above_1_percent_50R[i] = sum(weights_forecast_50R > 0.01)\n",
    "        leftover_weight[i] = 1-sum(weights_forecast[:num_above_1_percent[i]])\n",
    "    \n",
    "    mean_particles_above_1_percent[drifter_set_size-1] = num_above_1_percent.mean()\n",
    "    mean_particles_above_1_percent_10R[drifter_set_size-1] = num_above_1_percent_10R.mean()\n",
    "    mean_particles_above_1_percent_50R[drifter_set_size-1] = num_above_1_percent_50R.mean()\n",
    "    \n",
    "    print(np.array2string(best_weights[:,:8], max_line_width=400))\n",
    "    print(\"Number of particles with weight > 1%:\\n\" + str(num_above_1_percent))\n",
    "    print(\"Mean number of particles with weight > 1%: \" + str(num_above_1_percent.mean()))\n",
    "    print(\"Mean number of particles with weight > 1% with 10R: \" + str(num_above_1_percent_10R.mean()))\n",
    "    print(\"Mean number of particles with weight > 1% with 50R: \" + str(num_above_1_percent_50R.mean()))\n",
    "    print(\"Total weight on < 1%:\\n\" + str(leftover_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New results at day 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rc('text', usetex=True)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 3))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "Nd = 15\n",
    "\n",
    "major_ticks = np.arange(0, Nd, 2)\n",
    "ax.set_xticks(major_ticks)\n",
    "\n",
    "\n",
    "ax.semilogy(np.arange(1, Nd+1), mean_particles_above_1_percent[:Nd], 'x', label=r'original $R$')\n",
    "ax.semilogy(np.arange(1, Nd+1), mean_particles_above_1_percent_10R[:Nd], '+', label=r'$R$ scaled by factor 10')\n",
    "#ax.semilogy(np.arange(1, Nd+1), mean_particles_above_1_percent_50R[:Nd], '^', label=r'$R$ scaled by factor 50')\n",
    "#ax.semilogy(np.arange(1, Nd+1), np.ones_like(mean_particles_above_1_percent[:Nd]), ':')\n",
    "ax.yaxis.set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "ax.grid(which='major', linewidth=1)\n",
    "ax.grid(which='minor', linewidth=0.2)\n",
    "ax.legend()\n",
    "ax.set_ylabel(r'Mean \\# particles with $w_i > 1\\%$')\n",
    "ax.set_xlabel(r'\\# observed drifters')\n",
    "\n",
    "folder = '/media/havahol/Seagate Backup Plus Drive/gpu_ocean/june_25_truth/sir/'\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "filename = folder + 'sir_weight_distribution_' + timestamp \n",
    "plt.savefig(filename + '.png', bbox_inches='tight')\n",
    "plt.savefig(filename + '.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": false
  },
  "kernelspec": {
   "display_name": "Python [conda env:gpuocean] *",
   "language": "python",
   "name": "conda-env-gpuocean-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
